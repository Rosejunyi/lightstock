#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å·¥å…·ï¼ˆå«å¤§ç›˜æ•°æ®å¤„ç† + RS Ratingï¼‰- v4.0 å¢žå¼ºç‰ˆ

æ–°å¢žåŠŸèƒ½ï¼ˆv4.0ï¼‰ï¼š
1. æ·»åŠ  RS Raw è®¡ç®—ï¼ˆç›¸å¯¹å¼ºåº¦åŽŸå§‹å€¼ï¼‰
2. æ·»åŠ  RS Rating è®¡ç®—ï¼ˆå…¨å¸‚åœºæ¨ªå‘ç™¾åˆ†ä½æŽ’åï¼‰
3. æ·»åŠ  MA50, MA150, MA200 å‡çº¿
4. RS æŒ‡æ ‡åŒæ—¶é€‚ç”¨äºŽä¸ªè‚¡å’Œå¤§ç›˜æŒ‡æ•°

ä¿ç•™åŠŸèƒ½ï¼ˆv3.0ï¼‰ï¼š
1. åŒæ—¶å¤„ç†ä¸ªè‚¡å’Œå¤§ç›˜æŒ‡æ•°æ•°æ®
2. å¤§ç›˜æ•°æ®ä¹Ÿè®¡ç®—å®Œæ•´çš„æŠ€æœ¯æŒ‡æ ‡
3. è¾“å‡ºåˆ°ç‹¬ç«‹çš„ index_indicators ç›®å½•
4. ä¿æŒåŽŸæœ‰æ‰€æœ‰åŠŸèƒ½

æ•°æ®æºï¼š
- ä¸ªè‚¡ï¼šdata/daily_parquet_qfq/
- å¤§ç›˜ï¼šdata/index_data/

è¾“å‡ºï¼š
- ä¸ªè‚¡æŒ‡æ ‡ï¼šdata/technical_indicators/
- å¤§ç›˜æŒ‡æ ‡ï¼šdata/index_indicators/

ä½œè€…ï¼šClaude
ç‰ˆæœ¬ï¼šv4.0ï¼ˆå¢žå¼ºç‰ˆï¼šå«RS Ratingï¼‰
æ—¥æœŸï¼š2025-11-01
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
from tqdm import tqdm
import logging
import multiprocessing as mp
from functools import partial
import warnings
warnings.filterwarnings('ignore')

# ============================================================
# é…ç½®
# ============================================================

# ç›®å½•é…ç½®
INPUT_STOCK_DIR = Path("data/daily_parquet_qfq")      # ä¸ªè‚¡å‰å¤æƒKçº¿æ•°æ®
INPUT_INDEX_DIR = Path("data/index_data")              # å¤§ç›˜æŒ‡æ•°æ•°æ®
OUTPUT_STOCK_DIR = Path("data/technical_indicators")   # ä¸ªè‚¡æŠ€æœ¯æŒ‡æ ‡è¾“å‡º
OUTPUT_INDEX_DIR = Path("data/index_indicators")       # å¤§ç›˜æŠ€æœ¯æŒ‡æ ‡è¾“å‡º
LOG_DIR = Path("logs")

# è®¡ç®—é…ç½®
USE_MULTIPROCESSING = True      # æ˜¯å¦ä½¿ç”¨å¤šè¿›ç¨‹
NUM_PROCESSES = mp.cpu_count()  # è¿›ç¨‹æ•°
BATCH_SIZE = 100                # æ‰¹å¤„ç†å¤§å°

# å°æ•°ä½æ•°é…ç½®
DECIMAL_CONFIG = {
    'ma': 2,           # ç§»åŠ¨å¹³å‡çº¿ï¼š2ä½å°æ•°
    'rsi': 2,          # RSIï¼š2ä½å°æ•°
    'macd': 4,         # MACDï¼š4ä½å°æ•°
    'kdj': 4,          # KDJï¼š4ä½å°æ•°
    'change': 2,       # æ¶¨è·Œå¹…ï¼š2ä½å°æ•°
    'volume': 2,       # æˆäº¤é‡æŒ‡æ ‡ï¼š2ä½å°æ•°
    'price': 2,        # ä»·æ ¼åŒºé—´ï¼š2ä½å°æ•°
    'rs_rating': 1,    # RS Ratingï¼š1ä½å°æ•°ï¼ˆç™¾åˆ†ä½ï¼‰
    'rs_raw': 4,       # RSåŽŸå§‹å€¼ï¼š4ä½å°æ•°
}

# åˆ›å»ºç›®å½•
OUTPUT_STOCK_DIR.mkdir(parents=True, exist_ok=True)
OUTPUT_INDEX_DIR.mkdir(parents=True, exist_ok=True)
LOG_DIR.mkdir(parents=True, exist_ok=True)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(
            LOG_DIR / f'calculate_indicators_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log',
            encoding='utf-8'
        ),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ============================================================
# åˆ—åæ ‡å‡†åŒ–
# ============================================================

def normalize_columns(df, is_index=False):
    """
    æ ‡å‡†åŒ–åˆ—å - è½¬æ¢ä¸ºä¸­æ–‡
    
    å‚æ•°ï¼š
    - is_index: æ˜¯å¦ä¸ºæŒ‡æ•°æ•°æ®ï¼ˆå½±å“è‚¡ç¥¨ä»£ç å­—æ®µåï¼‰
    """
    if is_index:
        rename_map = {
            'index_code': 'æŒ‡æ•°ä»£ç ',
            'index_name': 'æŒ‡æ•°åç§°',
            'symbol': 'æŒ‡æ•°ä»£ç ',
            'name': 'æŒ‡æ•°åç§°',
            'date': 'æ—¥æœŸ',
            'open': 'å¼€ç›˜',
            'high': 'æœ€é«˜',
            'low': 'æœ€ä½Ž',
            'close': 'æ”¶ç›˜',
            'volume': 'æˆäº¤é‡',
            'amount': 'æˆäº¤é¢',
            'turnover': 'æ¢æ‰‹çŽ‡',
            'pct_change': 'æ¶¨è·Œå¹…',
        }
    else:
        rename_map = {
            'symbol': 'è‚¡ç¥¨ä»£ç ',
            'date': 'æ—¥æœŸ',
            'open': 'å¼€ç›˜',
            'high': 'æœ€é«˜',
            'low': 'æœ€ä½Ž',
            'close': 'æ”¶ç›˜',
            'volume': 'æˆäº¤é‡',
            'amount': 'æˆäº¤é¢',
            'turnover': 'æ¢æ‰‹çŽ‡',
            'pct_change': 'æ¶¨è·Œå¹…',
            'name': 'è‚¡ç¥¨åç§°',
        }
    
    df = df.rename(columns=rename_map)
    
    # æ£€æŸ¥å¿…éœ€å­—æ®µ
    required = ['æ—¥æœŸ', 'å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½Ž', 'æ”¶ç›˜', 'æˆäº¤é‡']
    for col in required:
        if col not in df.columns:
            raise ValueError(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {col}")
    
    return df

def convert_to_english_for_calculation(df, is_index=False):
    """è®¡ç®—æ—¶ä¸´æ—¶è½¬æ¢ä¸ºè‹±æ–‡åˆ—åï¼ˆä¾¿äºŽä»£ç å¤„ç†ï¼‰"""
    if is_index:
        rename_map = {
            'æŒ‡æ•°ä»£ç ': 'symbol',
            'æŒ‡æ•°åç§°': 'name',
            'æ—¥æœŸ': 'date',
            'å¼€ç›˜': 'open',
            'æœ€é«˜': 'high',
            'æœ€ä½Ž': 'low',
            'æ”¶ç›˜': 'close',
            'æˆäº¤é‡': 'volume',
            'æˆäº¤é¢': 'amount',
            'æ¢æ‰‹çŽ‡': 'turnover',
            'æ¶¨è·Œå¹…': 'pct_change',
        }
    else:
        rename_map = {
            'è‚¡ç¥¨ä»£ç ': 'symbol',
            'æ—¥æœŸ': 'date',
            'å¼€ç›˜': 'open',
            'æœ€é«˜': 'high',
            'æœ€ä½Ž': 'low',
            'æ”¶ç›˜': 'close',
            'æˆäº¤é‡': 'volume',
            'æˆäº¤é¢': 'amount',
            'æ¢æ‰‹çŽ‡': 'turnover',
            'æ¶¨è·Œå¹…': 'pct_change',
            'è‚¡ç¥¨åç§°': 'name',
        }
    return df.rename(columns=rename_map)

# ============================================================
# æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å‡½æ•°
# ============================================================

def calculate_ma(df, periods=[5, 10, 20, 30, 50, 60, 120, 150, 200, 250]):
    """
    è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
    
    æ–°å¢žï¼šma50, ma150, ma200ï¼ˆv4.0ï¼‰
    ä¿ç•™ï¼šma5, ma10, ma20, ma30, ma60, ma120, ma250ï¼ˆv3.0ï¼‰
    """
    for period in periods:
        df[f'ma{period}'] = df['close'].rolling(window=period).mean()
    return df

def calculate_rsi(df, periods=[6, 12, 14, 24]):
    """è®¡ç®—RSIï¼ˆç›¸å¯¹å¼ºå¼±æŒ‡æ ‡ï¼‰- å¤šå‘¨æœŸ"""
    for period in periods:
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
        
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        
        df[f'rsi{period}'] = rsi
    return df

def calculate_macd(df, fast=12, slow=26, signal=9):
    """è®¡ç®—MACD"""
    ema_fast = df['close'].ewm(span=fast, adjust=False).mean()
    ema_slow = df['close'].ewm(span=slow, adjust=False).mean()
    
    macd = ema_fast - ema_slow
    signal_line = macd.ewm(span=signal, adjust=False).mean()
    histogram = macd - signal_line
    
    df['macd_dif'] = macd
    df['macd_dea'] = signal_line
    df['macd'] = histogram  # ä¹Ÿå«MACDæŸ±
    df['macd_bar'] = histogram
    
    return df

def calculate_kdj(df, n=9, m1=3, m2=3):
    """è®¡ç®—KDJæŒ‡æ ‡"""
    low_min = df['low'].rolling(window=n).min()
    high_max = df['high'].rolling(window=n).max()
    
    rsv = (df['close'] - low_min) / (high_max - low_min) * 100
    
    k = rsv.ewm(alpha=1/m1, adjust=False).mean()
    d = k.ewm(alpha=1/m2, adjust=False).mean()
    j = 3 * k - 2 * d
    
    df['kdj_k'] = k
    df['kdj_d'] = d
    df['kdj_j'] = j
    
    return df

def calculate_price_changes(df, periods=[1, 5, 10, 20, 25, 30, 60, 120, 180, 250]):
    """è®¡ç®—ä¸åŒå‘¨æœŸçš„æ¶¨è·Œå¹…"""
    for period in periods:
        df[f'change_{period}d'] = df['close'].pct_change(period) * 100
    return df

def calculate_volume_indicators(df):
    """è®¡ç®—æˆäº¤é‡æŒ‡æ ‡"""
    # æˆäº¤é‡ç§»åŠ¨å¹³å‡
    df['volume_ma5'] = df['volume'].rolling(window=5).mean()
    df['volume_ma10'] = df['volume'].rolling(window=10).mean()
    df['volume_ma20'] = df['volume'].rolling(window=20).mean()
    df['volume_ma30'] = df['volume'].rolling(window=30).mean()
    
    # é‡æ¯”ï¼ˆ5æ—¥ï¼‰
    df['volume_ma60'] = df['volume'].rolling(window=60).mean()  # æ–°å¢ž
    df['volume_ma90'] = df['volume'].rolling(window=90).mean()  # æ–°å¢ž
    df['volume_ratio_5d'] = df['volume'] / df['volume'].rolling(window=5).mean()
    
    return df

def calculate_price_range(df):
    """è®¡ç®—ä»·æ ¼åŒºé—´ï¼ˆé«˜ä½Žç‚¹ï¼‰"""
    # 20æ—¥ã€60æ—¥ã€120æ—¥ã€250æ—¥é«˜ä½Žç‚¹
    for period in [20, 60, 120, 250]:
        df[f'high_{period}d'] = df['high'].rolling(window=period).max()
        df[f'low_{period}d'] = df['low'].rolling(window=period).min()
    
    # 52å‘¨é«˜ä½Žç‚¹ï¼ˆçº¦252ä¸ªäº¤æ˜“æ—¥ï¼‰
    df['high_52w'] = df['high'].rolling(window=252).max()
    df['low_52w'] = df['low'].rolling(window=252).min()
    
    return df

def calculate_rs_raw(df):
    """
    è®¡ç®—ç›¸å¯¹å¼ºåº¦åŽŸå§‹å€¼ (RS Raw) - v4.0 æ–°å¢ž
    
    åŽŸç†ï¼š
    1. è®¡ç®—ä¸åŒå‘¨æœŸçš„æ¶¨è·Œå¹…ï¼ˆ20æ—¥ã€60æ—¥ã€120æ—¥ã€250æ—¥ï¼‰
    2. åŠ æƒå¹³å‡ï¼ˆè¿‘æœŸæƒé‡æ›´é«˜ï¼‰
    3. å¾—åˆ°ç›¸å¯¹å¼ºåº¦åŽŸå§‹å€¼
    
    æ³¨ï¼š
    - ä¸ªè‚¡å’Œå¤§ç›˜éƒ½å¯ä»¥è®¡ç®—æ­¤å€¼
    - æŽ’åéœ€è¦åœ¨æ‰€æœ‰è‚¡ç¥¨è®¡ç®—å®ŒåŽç»Ÿä¸€å¤„ç†
    """
    # è®¡ç®—ä¸åŒå‘¨æœŸçš„æ¶¨è·Œå¹…
    periods = [20, 60, 120, 250]  # 1æœˆã€3æœˆã€6æœˆã€1å¹´
    weights = [0.4, 0.3, 0.2, 0.1]  # æƒé‡ï¼šè¿‘æœŸæƒé‡æ›´é«˜
    
    rs_values = []
    for period in periods:
        change = df['close'].pct_change(period)
        rs_values.append(change)
    
    # åŠ æƒå¹³å‡
    rs_raw = sum(w * rs for w, rs in zip(weights, rs_values))
    df['rs_raw'] = rs_raw
    
    return df

def round_indicators(df):
    """æŽ§åˆ¶æŒ‡æ ‡çš„å°æ•°ä½æ•°"""
    # MAç³»åˆ—
    ma_cols = [col for col in df.columns if col.startswith('ma') and col[2:].isdigit()]
    for col in ma_cols:
        df[col] = df[col].round(DECIMAL_CONFIG['ma'])
    
    # RSI
    rsi_cols = [col for col in df.columns if col.startswith('rsi')]
    for col in rsi_cols:
        df[col] = df[col].round(DECIMAL_CONFIG['rsi'])
    
    # MACDç³»åˆ—
    macd_cols = [col for col in df.columns if 'macd' in col.lower()]
    for col in macd_cols:
        df[col] = df[col].round(DECIMAL_CONFIG['macd'])
    
    # KDJç³»åˆ—
    kdj_cols = [col for col in df.columns if col.startswith('kdj_')]
    for col in kdj_cols:
        df[col] = df[col].round(DECIMAL_CONFIG['kdj'])
    
    # æ¶¨è·Œå¹…ç³»åˆ—
    change_cols = [col for col in df.columns if col.startswith('change_')]
    for col in change_cols:
        df[col] = df[col].round(DECIMAL_CONFIG['change'])
    
    # æˆäº¤é‡æŒ‡æ ‡
    volume_cols = [col for col in df.columns if 'volume' in col and col != 'volume' and col != 'æˆäº¤é‡']
    for col in volume_cols:
        df[col] = df[col].round(DECIMAL_CONFIG['volume'])
    
    # ä»·æ ¼åŒºé—´
    price_cols = [col for col in df.columns if 'high_' in col or 'low_' in col]
    for col in price_cols:
        df[col] = df[col].round(DECIMAL_CONFIG['price'])
    
    # RSåŽŸå§‹å€¼ï¼ˆv4.0æ–°å¢žï¼‰
    if 'rs_raw' in df.columns:
        df['rs_raw'] = df['rs_raw'].round(DECIMAL_CONFIG['rs_raw'])
    
    # RS Ratingï¼ˆç¨åŽè®¡ç®—ï¼‰
    if 'rs_rating' in df.columns:
        df['rs_rating'] = df['rs_rating'].round(DECIMAL_CONFIG['rs_rating'])
    
    return df

def calculate_all_indicators(df, is_index=False):
    """
    è®¡ç®—æ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡
    
    å‚æ•°ï¼š
    - df: åŽŸå§‹Kçº¿æ•°æ®
    - is_index: æ˜¯å¦ä¸ºæŒ‡æ•°æ•°æ®
    
    è¿”å›žï¼š
    - å¸¦æ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡çš„DataFrame
    """
    # è½¬æ¢ä¸ºè‹±æ–‡åˆ—åä¾¿äºŽè®¡ç®—
    df = convert_to_english_for_calculation(df, is_index=is_index)
    
    # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸæŽ’åº
    df = df.sort_values('date').reset_index(drop=True)
    
    # è®¡ç®—å„ç±»æŒ‡æ ‡
    df = calculate_ma(df)              # åŒ…å«æ–°å¢žçš„ma50, ma150, ma200
    df = calculate_rsi(df)
    df = calculate_macd(df)
    df = calculate_kdj(df)
    df = calculate_price_changes(df)
    df = calculate_volume_indicators(df)
    df = calculate_price_range(df)
    df = calculate_rs_raw(df)          # v4.0 æ–°å¢žï¼šRSåŽŸå§‹å€¼
    
    # æŽ§åˆ¶å°æ•°ä½æ•°
    df = round_indicators(df)
    
    # è½¬æ¢å›žä¸­æ–‡åˆ—å
    if is_index:
        rename_back = {
            'symbol': 'æŒ‡æ•°ä»£ç ',
            'name': 'æŒ‡æ•°åç§°',
            'date': 'æ—¥æœŸ',
            'open': 'å¼€ç›˜',
            'high': 'æœ€é«˜',
            'low': 'æœ€ä½Ž',
            'close': 'æ”¶ç›˜',
            'volume': 'æˆäº¤é‡',
            'amount': 'æˆäº¤é¢',
            'turnover': 'æ¢æ‰‹çŽ‡',
            'pct_change': 'æ¶¨è·Œå¹…',
        }
    else:
        rename_back = {
            'symbol': 'è‚¡ç¥¨ä»£ç ',
            'name': 'è‚¡ç¥¨åç§°',
            'date': 'æ—¥æœŸ',
            'open': 'å¼€ç›˜',
            'high': 'æœ€é«˜',
            'low': 'æœ€ä½Ž',
            'close': 'æ”¶ç›˜',
            'volume': 'æˆäº¤é‡',
            'amount': 'æˆäº¤é¢',
            'turnover': 'æ¢æ‰‹çŽ‡',
            'pct_change': 'æ¶¨è·Œå¹…',
        }
    
    df = df.rename(columns=rename_back)
    
    return df

# ============================================================
# å•ä¸ªæ–‡ä»¶å¤„ç†
# ============================================================

def process_single_file(file_path, is_index=False, output_dir=None):
    """
    å¤„ç†å•ä¸ªæ–‡ä»¶ï¼ˆä¸ªè‚¡æˆ–æŒ‡æ•°ï¼‰
    
    å‚æ•°ï¼š
    - file_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
    - is_index: æ˜¯å¦ä¸ºæŒ‡æ•°æ•°æ®
    - output_dir: è¾“å‡ºç›®å½•
    """
    try:
        # è¯»å–æ•°æ®
        df = pd.read_parquet(file_path)
        
        # æ ‡å‡†åŒ–åˆ—å
        df = normalize_columns(df, is_index=is_index)
        
        # è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
        df = calculate_all_indicators(df, is_index=is_index)
        
        # ä¿å­˜ç»“æžœ
        output_file = output_dir / file_path.name
        df.to_parquet(output_file, index=False)
        
        return {
            'file': file_path.name,
            'rows': len(df),
            'success': True
        }
    
    except Exception as e:
        logger.error(f"{file_path.name}: å¤„ç†å¤±è´¥ - {e}")
        return {
            'file': file_path.name,
            'success': False,
            'error': str(e)
        }

# ============================================================
# æ‰¹é‡å¤„ç†
# ============================================================

def process_batch(files, is_index=False, output_dir=None, desc="å¤„ç†è¿›åº¦"):
    """æ‰¹é‡å¤„ç†æ–‡ä»¶"""
    stats = {
        'total': len(files),
        'success': 0,
        'failed': 0
    }
    
    if USE_MULTIPROCESSING and NUM_PROCESSES > 1 and not is_index:
        # å¤šè¿›ç¨‹å¤„ç†ï¼ˆä»…ç”¨äºŽä¸ªè‚¡ï¼ŒæŒ‡æ•°æ–‡ä»¶å°‘ä¸éœ€è¦ï¼‰
        process_func = partial(process_single_file, is_index=is_index, output_dir=output_dir)
        
        with mp.Pool(processes=NUM_PROCESSES) as pool:
            results = list(tqdm(
                pool.imap(process_func, files),
                total=len(files),
                desc=desc
            ))
    else:
        # å•è¿›ç¨‹å¤„ç†
        results = []
        for file_path in tqdm(files, desc=desc):
            result = process_single_file(file_path, is_index=is_index, output_dir=output_dir)
            results.append(result)
    
    # ç»Ÿè®¡ç»“æžœ
    stats['success'] = sum(1 for r in results if r and r.get('success', False))
    stats['failed'] = stats['total'] - stats['success']
    
    return stats, results

# ============================================================
# RS Rating æŽ’åè®¡ç®—ï¼ˆv4.0 æ–°å¢žï¼‰
# ============================================================

def calculate_rs_rating_for_stocks():
    """
    è®¡ç®—ä¸ªè‚¡çš„ RS Rating æŽ’åï¼ˆç™¾åˆ†ä½ï¼‰
    
    åŽŸç†ï¼š
    1. è¯»å–æ‰€æœ‰ä¸ªè‚¡çš„ rs_raw å€¼
    2. æŒ‰æ¯ä¸ªäº¤æ˜“æ—¥è¿›è¡Œæ¨ªå‘æŽ’å
    3. è½¬æ¢ä¸ºç™¾åˆ†ä½ï¼ˆ0-100åˆ†ï¼‰
    4. æ›´æ–°å›žå„è‚¡ç¥¨æ–‡ä»¶
    
    è¿”å›žï¼š
        dict: ç»Ÿè®¡ä¿¡æ¯
    """
    print("\n" + "=" * 80)
    print("ç¬¬3éƒ¨åˆ†ï¼šè®¡ç®—ä¸ªè‚¡ RS Rating æŽ’å")
    print("=" * 80)
    
    # æ£€æŸ¥è¾“å‡ºç›®å½•
    if not OUTPUT_STOCK_DIR.exists():
        print(f"âŒ ä¸ªè‚¡æŒ‡æ ‡ç›®å½•ä¸å­˜åœ¨: {OUTPUT_STOCK_DIR}")
        return {'success': 0, 'failed': 0, 'total': 0}
    
    # èŽ·å–æ‰€æœ‰ä¸ªè‚¡æŒ‡æ ‡æ–‡ä»¶
    indicator_files = list(OUTPUT_STOCK_DIR.glob("*.parquet"))
    
    if not indicator_files:
        print(f"âŒ æœªæ‰¾åˆ°ä¸ªè‚¡æŒ‡æ ‡æ–‡ä»¶: {OUTPUT_STOCK_DIR}")
        return {'success': 0, 'failed': 0, 'total': 0}
    
    print(f"æ‰¾åˆ° {len(indicator_files)} ä¸ªä¸ªè‚¡æŒ‡æ ‡æ–‡ä»¶")
    
    # 1. è¯»å–æ‰€æœ‰æ–‡ä»¶çš„ rs_raw æ•°æ®
    print(f"\nðŸ“– è¯»å–æ•°æ®...")
    
    all_data = []
    failed_reads = 0
    
    for file in tqdm(indicator_files, desc="è¯»å–è¿›åº¦"):
        try:
            # åªè¯»å–å¿…è¦çš„åˆ—
            df = pd.read_parquet(file, columns=['è‚¡ç¥¨ä»£ç ', 'æ—¥æœŸ', 'rs_raw'])
            all_data.append(df)
        except Exception as e:
            logger.error(f"{file.name}: è¯»å–å¤±è´¥ - {e}")
            failed_reads += 1
    
    if not all_data:
        print("âŒ æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ•°æ®")
        return {'success': 0, 'failed': failed_reads, 'total': len(indicator_files)}
    
    print(f"âœ… æˆåŠŸè¯»å– {len(all_data)} ä¸ªæ–‡ä»¶")
    if failed_reads > 0:
        print(f"âš ï¸  è¯»å–å¤±è´¥ {failed_reads} ä¸ªæ–‡ä»¶")
    
    # 2. åˆå¹¶æ‰€æœ‰è‚¡ç¥¨æ•°æ®
    print(f"\nðŸ”— åˆå¹¶æ•°æ®...")
    combined = pd.concat(all_data, ignore_index=True)
    
    print(f"  æ€»è®°å½•æ•°: {len(combined):,}")
    print(f"  è‚¡ç¥¨æ•°é‡: {combined['è‚¡ç¥¨ä»£ç '].nunique():,}")
    print(f"  æ—¥æœŸèŒƒå›´: {combined['æ—¥æœŸ'].min()} ~ {combined['æ—¥æœŸ'].max()}")
    
    # 3. æ¸…ç†æ•°æ®
    original_count = len(combined)
    combined = combined.dropna(subset=['rs_raw'])
    dropped_count = original_count - len(combined)
    
    if dropped_count > 0:
        print(f"\n  æ¸…ç†ç©ºå€¼: åˆ é™¤ {dropped_count:,} æ¡è®°å½•")
    
    if len(combined) == 0:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„ rs_raw æ•°æ®")
        return {'success': 0, 'failed': failed_reads, 'total': len(indicator_files)}
    
    # 4. æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—ç™¾åˆ†ä½æŽ’å
    print(f"\nðŸ“Š è®¡ç®—æ¨ªå‘æŽ’å...")
    
    # ä½¿ç”¨ rank(pct=True) è®¡ç®—ç™¾åˆ†ä½ï¼Œä¹˜ä»¥100å¾—åˆ°0-100åˆ†
    # method='min'ï¼šç›¸åŒå€¼å–æœ€å°æŽ’åï¼Œæ›´ä¿å®ˆ
    combined['rs_rating'] = combined.groupby('æ—¥æœŸ')['rs_raw'].rank(pct=True, method='min') * 100
    
    # æŽ§åˆ¶å°æ•°ä½æ•°ï¼ˆ1ä½å°æ•°ï¼‰
    combined['rs_rating'] = combined['rs_rating'].round(DECIMAL_CONFIG['rs_rating'])
    
    unique_dates = combined['æ—¥æœŸ'].nunique()
    print(f"âœ… å®Œæˆ {unique_dates:,} ä¸ªäº¤æ˜“æ—¥çš„æŽ’åè®¡ç®—")
    
    # æ˜¾ç¤ºæŽ’ååˆ†å¸ƒ
    print(f"\n  RS Rating åˆ†å¸ƒç»Ÿè®¡:")
    print(f"    æœ€å°å€¼: {combined['rs_rating'].min():.1f}")
    print(f"    25åˆ†ä½: {combined['rs_rating'].quantile(0.25):.1f}")
    print(f"    ä¸­ä½æ•°: {combined['rs_rating'].quantile(0.50):.1f}")
    print(f"    75åˆ†ä½: {combined['rs_rating'].quantile(0.75):.1f}")
    print(f"    æœ€å¤§å€¼: {combined['rs_rating'].max():.1f}")
    
    # 5. æ›´æ–°å›žå„è‚¡ç¥¨æ–‡ä»¶
    print(f"\nðŸ’¾ æ›´æ–°æ–‡ä»¶...")
    
    grouped = combined.groupby('è‚¡ç¥¨ä»£ç ')
    
    success = 0
    failed = 0
    
    for symbol, group in tqdm(grouped, desc="æ›´æ–°è¿›åº¦"):
        try:
            file_path = OUTPUT_STOCK_DIR / f"{symbol}.parquet"
            
            if not file_path.exists():
                logger.warning(f"{symbol}: æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                failed += 1
                continue
            
            # è¯»å–åŽŸæ–‡ä»¶
            df_original = pd.read_parquet(file_path)
            
            # åˆ é™¤æ—§çš„ rs_ratingï¼ˆå¦‚æžœæœ‰ï¼‰
            if 'rs_rating' in df_original.columns:
                df_original = df_original.drop(columns=['rs_rating'])
            
            # åˆå¹¶æ–°çš„ rs_rating
            df_updated = df_original.merge(
                group[['æ—¥æœŸ', 'rs_rating']], 
                on='æ—¥æœŸ', 
                how='left'
            )
            
            # ç¡®ä¿åˆ—é¡ºåºï¼ˆrs_ratingæ”¾åœ¨æœ€åŽï¼‰
            cols = [col for col in df_updated.columns if col != 'rs_rating'] + ['rs_rating']
            df_updated = df_updated[cols]
            
            # ä¿å­˜
            df_updated.to_parquet(file_path, index=False)
            success += 1
            
        except Exception as e:
            logger.error(f"{symbol}: æ›´æ–°å¤±è´¥ - {e}")
            failed += 1
    
    # 6. ç»Ÿè®¡ç»“æžœ
    stats = {
        'total': len(indicator_files),
        'success': success,
        'failed': failed
    }
    
    print(f"\nâœ… ä¸ªè‚¡ RS Rating æ›´æ–°å®Œæˆ")
    print(f"  æ›´æ–°æˆåŠŸ: {stats['success']}/{stats['total']}")
    if stats['failed'] > 0:
        print(f"  æ›´æ–°å¤±è´¥: {stats['failed']}")
    
    return stats

def calculate_rs_rating_for_indexes():
    """
    è®¡ç®—å¤§ç›˜æŒ‡æ•°çš„ RS Rating æŽ’åï¼ˆç™¾åˆ†ä½ï¼‰
    
    æ³¨ï¼šå¤§ç›˜æŒ‡æ•°ä¹‹é—´ä¹Ÿå¯ä»¥è¿›è¡Œç›¸å¯¹å¼ºåº¦æ¯”è¾ƒ
    """
    print("\n" + "=" * 80)
    print("ç¬¬4éƒ¨åˆ†ï¼šè®¡ç®—å¤§ç›˜ RS Rating æŽ’å")
    print("=" * 80)
    
    # æ£€æŸ¥è¾“å‡ºç›®å½•
    if not OUTPUT_INDEX_DIR.exists():
        print(f"âŒ å¤§ç›˜æŒ‡æ ‡ç›®å½•ä¸å­˜åœ¨: {OUTPUT_INDEX_DIR}")
        return {'success': 0, 'failed': 0, 'total': 0}
    
    # èŽ·å–æ‰€æœ‰æŒ‡æ•°æŒ‡æ ‡æ–‡ä»¶
    indicator_files = list(OUTPUT_INDEX_DIR.glob("*.parquet"))
    
    if not indicator_files:
        print(f"âš ï¸  æœªæ‰¾åˆ°å¤§ç›˜æŒ‡æ ‡æ–‡ä»¶: {OUTPUT_INDEX_DIR}")
        return {'success': 0, 'failed': 0, 'total': 0}
    
    print(f"æ‰¾åˆ° {len(indicator_files)} ä¸ªå¤§ç›˜æŒ‡æ ‡æ–‡ä»¶")
    
    # 1. è¯»å–æ‰€æœ‰æ–‡ä»¶çš„ rs_raw æ•°æ®
    print(f"\nðŸ“– è¯»å–æ•°æ®...")
    
    all_data = []
    failed_reads = 0
    
    for file in tqdm(indicator_files, desc="è¯»å–è¿›åº¦"):
        try:
            # åªè¯»å–å¿…è¦çš„åˆ—
            df = pd.read_parquet(file, columns=['æŒ‡æ•°ä»£ç ', 'æ—¥æœŸ', 'rs_raw'])
            # ä¸´æ—¶é‡å‘½åä¸ºç»Ÿä¸€æ ¼å¼
            df = df.rename(columns={'æŒ‡æ•°ä»£ç ': 'ä»£ç '})
            all_data.append(df)
        except Exception as e:
            logger.error(f"{file.name}: è¯»å–å¤±è´¥ - {e}")
            failed_reads += 1
    
    if not all_data:
        print("âŒ æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•æ•°æ®")
        return {'success': 0, 'failed': failed_reads, 'total': len(indicator_files)}
    
    print(f"âœ… æˆåŠŸè¯»å– {len(all_data)} ä¸ªæ–‡ä»¶")
    if failed_reads > 0:
        print(f"âš ï¸  è¯»å–å¤±è´¥ {failed_reads} ä¸ªæ–‡ä»¶")
    
    # 2. åˆå¹¶æ‰€æœ‰æŒ‡æ•°æ•°æ®
    print(f"\nðŸ”— åˆå¹¶æ•°æ®...")
    combined = pd.concat(all_data, ignore_index=True)
    
    print(f"  æ€»è®°å½•æ•°: {len(combined):,}")
    print(f"  æŒ‡æ•°æ•°é‡: {combined['ä»£ç '].nunique():,}")
    print(f"  æ—¥æœŸèŒƒå›´: {combined['æ—¥æœŸ'].min()} ~ {combined['æ—¥æœŸ'].max()}")
    
    # 3. æ¸…ç†æ•°æ®
    original_count = len(combined)
    combined = combined.dropna(subset=['rs_raw'])
    dropped_count = original_count - len(combined)
    
    if dropped_count > 0:
        print(f"\n  æ¸…ç†ç©ºå€¼: åˆ é™¤ {dropped_count:,} æ¡è®°å½•")
    
    if len(combined) == 0:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„ rs_raw æ•°æ®")
        return {'success': 0, 'failed': failed_reads, 'total': len(indicator_files)}
    
    # 4. æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—ç™¾åˆ†ä½æŽ’å
    print(f"\nðŸ“Š è®¡ç®—æ¨ªå‘æŽ’å...")
    
    combined['rs_rating'] = combined.groupby('æ—¥æœŸ')['rs_raw'].rank(pct=True, method='min') * 100
    combined['rs_rating'] = combined['rs_rating'].round(DECIMAL_CONFIG['rs_rating'])
    
    unique_dates = combined['æ—¥æœŸ'].nunique()
    print(f"âœ… å®Œæˆ {unique_dates:,} ä¸ªäº¤æ˜“æ—¥çš„æŽ’åè®¡ç®—")
    
    # æ˜¾ç¤ºæŽ’ååˆ†å¸ƒ
    print(f"\n  RS Rating åˆ†å¸ƒç»Ÿè®¡:")
    print(f"    æœ€å°å€¼: {combined['rs_rating'].min():.1f}")
    print(f"    25åˆ†ä½: {combined['rs_rating'].quantile(0.25):.1f}")
    print(f"    ä¸­ä½æ•°: {combined['rs_rating'].quantile(0.50):.1f}")
    print(f"    75åˆ†ä½: {combined['rs_rating'].quantile(0.75):.1f}")
    print(f"    æœ€å¤§å€¼: {combined['rs_rating'].max():.1f}")
    
    # 5. æ›´æ–°å›žå„æŒ‡æ•°æ–‡ä»¶
    print(f"\nðŸ’¾ æ›´æ–°æ–‡ä»¶...")
    
    grouped = combined.groupby('ä»£ç ')
    
    success = 0
    failed = 0
    
    for symbol, group in tqdm(grouped, desc="æ›´æ–°è¿›åº¦"):
        try:
            file_path = OUTPUT_INDEX_DIR / f"{symbol}.parquet"
            
            if not file_path.exists():
                logger.warning(f"{symbol}: æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                failed += 1
                continue
            
            # è¯»å–åŽŸæ–‡ä»¶
            df_original = pd.read_parquet(file_path)
            
            # åˆ é™¤æ—§çš„ rs_ratingï¼ˆå¦‚æžœæœ‰ï¼‰
            if 'rs_rating' in df_original.columns:
                df_original = df_original.drop(columns=['rs_rating'])
            
            # åˆå¹¶æ–°çš„ rs_rating
            df_updated = df_original.merge(
                group[['æ—¥æœŸ', 'rs_rating']], 
                on='æ—¥æœŸ', 
                how='left'
            )
            
            # ç¡®ä¿åˆ—é¡ºåºï¼ˆrs_ratingæ”¾åœ¨æœ€åŽï¼‰
            cols = [col for col in df_updated.columns if col != 'rs_rating'] + ['rs_rating']
            df_updated = df_updated[cols]
            
            # ä¿å­˜
            df_updated.to_parquet(file_path, index=False)
            success += 1
            
        except Exception as e:
            logger.error(f"{symbol}: æ›´æ–°å¤±è´¥ - {e}")
            failed += 1
    
    # 6. ç»Ÿè®¡ç»“æžœ
    stats = {
        'total': len(indicator_files),
        'success': success,
        'failed': failed
    }
    
    print(f"\nâœ… å¤§ç›˜ RS Rating æ›´æ–°å®Œæˆ")
    print(f"  æ›´æ–°æˆåŠŸ: {stats['success']}/{stats['total']}")
    if stats['failed'] > 0:
        print(f"  æ›´æ–°å¤±è´¥: {stats['failed']}")
    
    return stats

# ============================================================
# ä¸»ç¨‹åº
# ============================================================

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("  å®Œæ•´æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å·¥å…· v4.0 å¢žå¼ºç‰ˆ")
    print("  æ–°å¢žï¼šRS Raw + RS Rating + MA50/150/200")
    print("  ä¿ç•™ï¼šå¤§ç›˜æŒ‡æ•°å¤„ç† + æ‰€æœ‰åŽŸæœ‰åŠŸèƒ½")
    print("=" * 80)
    
    # ========================================
    # ç¬¬1éƒ¨åˆ†ï¼šå¤„ç†ä¸ªè‚¡æ•°æ®
    # ========================================
    print("\n" + "=" * 80)
    print("ç¬¬1éƒ¨åˆ†ï¼šå¤„ç†ä¸ªè‚¡æ•°æ®")
    print("=" * 80)
    
    if not INPUT_STOCK_DIR.exists():
        print(f"âŒ ä¸ªè‚¡æ•°æ®ç›®å½•ä¸å­˜åœ¨: {INPUT_STOCK_DIR}")
        stock_stats = {'total': 0, 'success': 0, 'failed': 0}
    else:
        stock_files = list(INPUT_STOCK_DIR.glob("*.parquet"))
        print(f"æ‰¾åˆ° {len(stock_files)} ä¸ªä¸ªè‚¡æ–‡ä»¶")
        
        if stock_files:
            stock_stats, _ = process_batch(
                stock_files, 
                is_index=False, 
                output_dir=OUTPUT_STOCK_DIR,
                desc="ä¸ªè‚¡å¤„ç†"
            )
            
            print(f"\nâœ… ä¸ªè‚¡å¤„ç†å®Œæˆ")
            print(f"  æˆåŠŸ: {stock_stats['success']}/{stock_stats['total']}")
            if stock_stats['failed'] > 0:
                print(f"  å¤±è´¥: {stock_stats['failed']}")
        else:
            print(f"âŒ æœªæ‰¾åˆ°ä¸ªè‚¡æ•°æ®æ–‡ä»¶")
            stock_stats = {'total': 0, 'success': 0, 'failed': 0}
    
    # ========================================
    # ç¬¬2éƒ¨åˆ†ï¼šå¤„ç†å¤§ç›˜æŒ‡æ•°æ•°æ®
    # ========================================
    print("\n" + "=" * 80)
    print("ç¬¬2éƒ¨åˆ†ï¼šå¤„ç†å¤§ç›˜æŒ‡æ•°æ•°æ®")
    print("=" * 80)
    
    if not INPUT_INDEX_DIR.exists():
        print(f"âŒ å¤§ç›˜æ•°æ®ç›®å½•ä¸å­˜åœ¨: {INPUT_INDEX_DIR}")
        index_stats = {'total': 0, 'success': 0, 'failed': 0}
    else:
        index_files = list(INPUT_INDEX_DIR.glob("*.parquet"))
        print(f"æ‰¾åˆ° {len(index_files)} ä¸ªæŒ‡æ•°æ–‡ä»¶")
        
        if index_files:
            index_stats, _ = process_batch(
                index_files, 
                is_index=True, 
                output_dir=OUTPUT_INDEX_DIR,
                desc="æŒ‡æ•°å¤„ç†"
            )
            
            print(f"\nâœ… æŒ‡æ•°å¤„ç†å®Œæˆ")
            print(f"  æˆåŠŸ: {index_stats['success']}/{index_stats['total']}")
            if index_stats['failed'] > 0:
                print(f"  å¤±è´¥: {index_stats['failed']}")
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ°æŒ‡æ•°æ•°æ®æ–‡ä»¶")
            index_stats = {'total': 0, 'success': 0, 'failed': 0}
    
    # ========================================
    # ç¬¬3éƒ¨åˆ†ï¼šè®¡ç®—ä¸ªè‚¡ RS Rating æŽ’å
    # ========================================
    stock_rs_stats = {'success': 0, 'failed': 0, 'total': 0}
    if stock_stats['success'] > 0:
        stock_rs_stats = calculate_rs_rating_for_stocks()
    else:
        print("\nâš ï¸  è·³è¿‡ä¸ªè‚¡ RS Rating è®¡ç®—ï¼ˆæ— æˆåŠŸå¤„ç†çš„ä¸ªè‚¡æ•°æ®ï¼‰")
    
    # ========================================
    # ç¬¬4éƒ¨åˆ†ï¼šè®¡ç®—å¤§ç›˜ RS Rating æŽ’å
    # ========================================
    index_rs_stats = {'success': 0, 'failed': 0, 'total': 0}
    if index_stats['success'] > 0:
        index_rs_stats = calculate_rs_rating_for_indexes()
    else:
        print("\nâš ï¸  è·³è¿‡å¤§ç›˜ RS Rating è®¡ç®—ï¼ˆæ— æˆåŠŸå¤„ç†çš„å¤§ç›˜æ•°æ®ï¼‰")
    
    # ========================================
    # å®Œæˆç»Ÿè®¡
    # ========================================
    print("\n" + "=" * 80)
    print("è®¡ç®—å®Œæˆç»Ÿè®¡")
    print("=" * 80)
    print(f"ä¸ªè‚¡:")
    print(f"  æ€»æ•°: {stock_stats['total']}")
    print(f"  âœ… æŒ‡æ ‡è®¡ç®—æˆåŠŸ: {stock_stats['success']}")
    print(f"  âœ… RS RatingæˆåŠŸ: {stock_rs_stats['success']}")
    if stock_stats['failed'] > 0 or stock_rs_stats['failed'] > 0:
        print(f"  âŒ å¤±è´¥: {stock_stats['failed'] + stock_rs_stats['failed']}")
    
    print(f"\næŒ‡æ•°:")
    print(f"  æ€»æ•°: {index_stats['total']}")
    print(f"  âœ… æŒ‡æ ‡è®¡ç®—æˆåŠŸ: {index_stats['success']}")
    print(f"  âœ… RS RatingæˆåŠŸ: {index_rs_stats['success']}")
    if index_stats['failed'] > 0 or index_rs_stats['failed'] > 0:
        print(f"  âŒ å¤±è´¥: {index_stats['failed'] + index_rs_stats['failed']}")
    
    print(f"\næ€»è®¡:")
    total_success = stock_stats['success'] + index_stats['success'] + stock_rs_stats['success'] + index_rs_stats['success']
    total_failed = stock_stats['failed'] + index_stats['failed'] + stock_rs_stats['failed'] + index_rs_stats['failed']
    print(f"  âœ… æˆåŠŸ: {total_success}")
    if total_failed > 0:
        print(f"  âŒ å¤±è´¥: {total_failed}")
    print("=" * 80)
    
    # ========================================
    # æ•°æ®ç¤ºä¾‹å±•ç¤º
    # ========================================
    if stock_stats['success'] > 0:
        print("\n" + "=" * 80)
        print("ðŸ“Š ä¸ªè‚¡æ•°æ®ç¤ºä¾‹")
        print("=" * 80)
        
        sample_file = list(OUTPUT_STOCK_DIR.glob("*.parquet"))[0]
        sample_df = pd.read_parquet(sample_file)
        
        print(f"\næ–‡ä»¶: {sample_file.name}")
        print(f"  æ•°æ®è¡Œæ•°: {len(sample_df):,}")
        print(f"  æŒ‡æ ‡æ•°é‡: {len(sample_df.columns)}")
        
        print(f"\n  æœ€æ–°5æ¡è®°å½•:")
        display_cols = ['æ—¥æœŸ', 'æ”¶ç›˜', 'ma5', 'ma20', 'ma60', 'ma150', 'rsi14', 'rs_raw', 'rs_rating', 'change_60d']
        available_cols = [col for col in display_cols if col in sample_df.columns]
        print(sample_df[available_cols].tail(5).to_string(index=False))
    
    if index_stats['success'] > 0:
        print("\n" + "=" * 80)
        print("ðŸ“Š æŒ‡æ•°æ•°æ®ç¤ºä¾‹")
        print("=" * 80)
        
        sample_file = list(OUTPUT_INDEX_DIR.glob("*.parquet"))[0]
        sample_df = pd.read_parquet(sample_file)
        
        print(f"\næ–‡ä»¶: {sample_file.name}")
        print(f"  æ•°æ®è¡Œæ•°: {len(sample_df):,}")
        print(f"  æŒ‡æ ‡æ•°é‡: {len(sample_df.columns)}")
        
        print(f"\n  æœ€æ–°5æ¡è®°å½•:")
        display_cols = ['æ—¥æœŸ', 'æ”¶ç›˜', 'ma5', 'ma20', 'ma60', 'ma150', 'rsi14', 'rs_raw', 'rs_rating', 'change_60d']
        available_cols = [col for col in display_cols if col in sample_df.columns]
        print(sample_df[available_cols].tail(5).to_string(index=False))
    
    # ========================================
    # ä½¿ç”¨è¯´æ˜Ž
    # ========================================
    print("\n" + "=" * 80)
    print("âœ… æ‰€æœ‰è®¡ç®—å®Œæˆï¼")
    print("=" * 80)
    print(f"ðŸ’¾ ä¸ªè‚¡æŒ‡æ ‡: {OUTPUT_STOCK_DIR}")
    print(f"ðŸ’¾ å¤§ç›˜æŒ‡æ ‡: {OUTPUT_INDEX_DIR}")
    print(f"ðŸ“ æ—¥å¿—æ–‡ä»¶: {LOG_DIR}/calculate_indicators_*.log")
    
    print("\n" + "=" * 80)
    print("v4.0 æ–°å¢žåŠŸèƒ½")
    print("=" * 80)
    print("""
âœ… æ–°å¢žæŒ‡æ ‡ï¼ˆä¸ªè‚¡å’Œå¤§ç›˜éƒ½æœ‰ï¼‰ï¼š
1. RS Rawï¼ˆrs_rawï¼‰ï¼šç›¸å¯¹å¼ºåº¦åŽŸå§‹å€¼
   - è®¡ç®—æ–¹å¼ï¼šåŠ æƒå¹³å‡å¤šå‘¨æœŸæ¶¨å¹…
   - å…¬å¼ï¼š0.4Ã—change_20d + 0.3Ã—change_60d + 0.2Ã—change_120d + 0.1Ã—change_250d
   - ç”¨é€”ï¼šè¡¡é‡ä¸ªè‚¡/æŒ‡æ•°çš„ç»¼åˆå¼ºåº¦

2. RS Ratingï¼ˆrs_ratingï¼‰ï¼šç›¸å¯¹å¼ºåº¦ç™¾åˆ†ä½æŽ’å
   - èŒƒå›´ï¼š0.0 - 100.0
   - å«ä¹‰ï¼šè¯¥è‚¡ç¥¨/æŒ‡æ•°å¼ºäºŽå¤šå°‘ç™¾åˆ†æ¯”çš„åŒç±»æ ‡çš„
   - è®¡ç®—ï¼šæ¯ä¸ªäº¤æ˜“æ—¥å¯¹æ‰€æœ‰æ ‡çš„çš„rs_rawè¿›è¡Œæ¨ªå‘æŽ’å
   - è¯„çº§å‚è€ƒï¼š
     * 80+ åˆ†ï¼šå¼ºåŠ¿è‚¡/å¼ºåŠ¿æŒ‡æ•°
     * 60-80åˆ†ï¼šä¸­ç­‰åå¼º
     * 40-60åˆ†ï¼šä¸­æ€§
     * 20-40åˆ†ï¼šä¸­ç­‰åå¼±
     * 0-20åˆ†ï¼šå¼±åŠ¿è‚¡/å¼±åŠ¿æŒ‡æ•°

3. æ–°å¢žå‡çº¿ï¼š
   - ma50ï¼š50æ—¥å‡çº¿
   - ma150ï¼š150æ—¥å‡çº¿
   - ma200ï¼š200æ—¥å‡çº¿

âœ… ä¿ç•™çš„æ‰€æœ‰åŽŸæœ‰åŠŸèƒ½ï¼š
1. ç§»åŠ¨å¹³å‡çº¿: ma5, ma10, ma20, ma30, ma60, ma120, ma250
2. RSIæŒ‡æ ‡: rsi6, rsi12, rsi14, rsi24
3. MACD: macd_dif, macd_dea, macd, macd_bar
4. KDJ: kdj_k, kdj_d, kdj_j
5. æ¶¨è·Œå¹…: change_1d, change_5d, change_10d, change_20d, change_25d, 
          change_30d, change_60d, change_120d, change_180d, change_250d
6. æˆäº¤é‡: volume_ma5, volume_ma10, volume_ma20, volume_ma30, volume_ratio_5d
7. ä»·æ ¼åŒºé—´: high_20d, high_60d, high_120d, high_250d, high_52w,
            low_20d, low_60d, low_120d, low_250d, low_52w

ä½¿ç”¨ç¤ºä¾‹ï¼š
```python
import pandas as pd

# è¯»å–ä¸ªè‚¡æŒ‡æ ‡ï¼ˆå«RS Ratingï¼‰
stock_df = pd.read_parquet('data/technical_indicators/000001.parquet')
print(f"RS Rating: {stock_df['rs_rating'].iloc[-1]}")  # æœ€æ–°RSè¯„åˆ†
print(f"RS Raw: {stock_df['rs_raw'].iloc[-1]}")        # RSåŽŸå§‹å€¼
print(f"MA150: {stock_df['ma150'].iloc[-1]}")          # 150æ—¥å‡çº¿

# è¯»å–å¤§ç›˜æŒ‡æ ‡ï¼ˆå«RS Ratingï¼‰
index_df = pd.read_parquet('data/index_indicators/000001.SH.parquet')
print(f"å¤§ç›˜RS Rating: {index_df['rs_rating'].iloc[-1]}")

# ç­›é€‰å¼ºåŠ¿è‚¡ï¼ˆRS Rating > 80ï¼‰
strong_stocks = stock_df[stock_df['rs_rating'] > 80]

# åˆ¤æ–­è‚¡ç¥¨æ˜¯å¦è·‘èµ¢å¤§ç›˜
if stock_df['change_60d'].iloc[-1] > index_df['change_60d'].iloc[-1]:
    print("è¯¥è‚¡ç¥¨è·‘èµ¢å¤§ç›˜ï¼")
```

æ³¨æ„äº‹é¡¹ï¼š
1. RS Ratingæ˜¯æ¨ªå‘æŽ’åï¼Œæ¯ä¸ªäº¤æ˜“æ—¥é‡æ–°è®¡ç®—
2. ä¸ªè‚¡ä¹‹é—´æ¯”è¾ƒç”¨ä¸ªè‚¡çš„RS Rating
3. æŒ‡æ•°ä¹‹é—´æ¯”è¾ƒç”¨æŒ‡æ•°çš„RS Rating
4. RS Rawå’ŒRS Ratingéƒ½éœ€è¦è‡³å°‘250å¤©åŽ†å²æ•°æ®
5. æ‰€æœ‰åŽŸæœ‰åŠŸèƒ½å’Œè¾“å‡ºç›®å½•ä¿æŒä¸å˜
    """)
    
    return 0 if total_success > 0 else 1

if __name__ == "__main__":
    exit(main())
