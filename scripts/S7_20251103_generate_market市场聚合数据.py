#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¸‚åœºèšåˆæ•°æ®ç”Ÿæˆè„šæœ¬ v1.0

åŠŸèƒ½ï¼š
1. æ¯æ—¥å¸‚åœºç»Ÿè®¡ï¼ˆæ¶¨è·Œå®¶æ•°ã€å¸‚åœºå¹³å‡æ¶¨å¹…ç­‰ï¼‰
2. æ¿å—è½®åŠ¨åˆ†æï¼ˆå„æ¿å—è¡¨ç°å¯¹æ¯”ï¼‰
3. å†å²æ’åè¿½è¸ªï¼ˆRS Ratingã€æ¶¨å¹…ç­‰æ’åå˜åŒ–ï¼‰

ç”¨é€”ï¼š
- å¸‚åœºæƒ…ç»ªåˆ¤æ–­ï¼ˆæ‹©æ—¶ï¼‰
- æ¿å—è½®åŠ¨ç­–ç•¥
- é¾™å¤´è‚¡è¯†åˆ«
- å†å²è¡¨ç°å¯¹æ¯”

æ•°æ®è¾“å‡ºï¼š
data/market_aggregates/
  â”œâ”€â”€ daily_stats.parquet       # æ¯æ—¥å¸‚åœºç»Ÿè®¡
  â”œâ”€â”€ sector_rotation.parquet   # æ¿å—è½®åŠ¨ï¼ˆå¾…å®ç°ï¼‰
  â””â”€â”€ ranking_history.parquet   # æ’åå†å²

ä½œè€…ï¼šClaude
ç‰ˆæœ¬ï¼šv1.0
æ—¥æœŸï¼š2025-11-03
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
from tqdm import tqdm
import logging
import warnings
warnings.filterwarnings('ignore')

# ============================================================
# é…ç½®
# ============================================================

# ç›®å½•é…ç½®
SNAPSHOT_DIR = Path("data/daily_snapshot")
AGGREGATES_DIR = Path("data/market_aggregates")
LOG_DIR = Path("logs")

# åˆ›å»ºç›®å½•
AGGREGATES_DIR.mkdir(parents=True, exist_ok=True)
LOG_DIR.mkdir(parents=True, exist_ok=True)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(
            LOG_DIR / f'market_aggregates_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log',
            encoding='utf-8'
        ),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


# ============================================================
# 1. æ¯æ—¥å¸‚åœºç»Ÿè®¡
# ============================================================

def generate_daily_stats(snapshot_date=None):
    """
    ç”Ÿæˆæ¯æ—¥å¸‚åœºç»Ÿè®¡
    
    ç»Ÿè®¡æŒ‡æ ‡ï¼š
    - æ¶¨è·Œå®¶æ•°ç»Ÿè®¡
    - æ¶¨è·Œåœç»Ÿè®¡
    - å¸‚åœºå¹³å‡æ¶¨è·Œå¹…
    - æˆäº¤é‡å’Œæ¢æ‰‹ç‡ç»Ÿè®¡
    - RS Ratingåˆ†å¸ƒ
    """
    
    print("\n" + "=" * 80)
    print("  ç”Ÿæˆæ¯æ—¥å¸‚åœºç»Ÿè®¡")
    print("=" * 80)
    
    # åŠ è½½å¿«ç…§
    snapshot_file = SNAPSHOT_DIR / "latest.parquet"
    if not snapshot_file.exists():
        if snapshot_date:
            snapshot_file = SNAPSHOT_DIR / f"snapshot_{snapshot_date}.parquet"
        
        if not snapshot_file.exists():
            print(f"âŒ æœªæ‰¾åˆ°å¿«ç…§æ–‡ä»¶: {snapshot_file}")
            return None
    
    print(f"è¯»å–å¿«ç…§: {snapshot_file.name}")
    df = pd.read_parquet(snapshot_file)
    
    if df.empty:
        print("âŒ å¿«ç…§æ•°æ®ä¸ºç©º")
        return None
    
    # æ ‡å‡†åŒ–åˆ—å
    rename_map = {
        'æ—¥æœŸ': 'date',
        'è‚¡ç¥¨ä»£ç ': 'symbol',
        'æ¶¨è·Œå¹…': 'pct_change',
        'æˆäº¤é‡': 'volume',
        'æˆäº¤é¢': 'amount',
        'æ¢æ‰‹ç‡': 'turnover',
    }
    df = df.rename(columns=rename_map)
    
    # è·å–æ—¥æœŸ
    if 'date' in df.columns:
        stat_date = df['date'].iloc[0]
        if isinstance(stat_date, str):
            stat_date = stat_date
        else:
            stat_date = stat_date.strftime('%Y-%m-%d')
    else:
        stat_date = datetime.now().strftime('%Y-%m-%d')
    
    print(f"ç»Ÿè®¡æ—¥æœŸ: {stat_date}")
    print(f"è‚¡ç¥¨æ•°é‡: {len(df)}")
    
    # å¼€å§‹ç»Ÿè®¡
    stats = {'æ—¥æœŸ': stat_date}
    
    # 1. æ¶¨è·Œå®¶æ•°ç»Ÿè®¡
    if 'pct_change' in df.columns:
        df['pct_change'] = pd.to_numeric(df['pct_change'], errors='coerce')
        
        stats['ä¸Šæ¶¨å®¶æ•°'] = (df['pct_change'] > 0).sum()
        stats['ä¸‹è·Œå®¶æ•°'] = (df['pct_change'] < 0).sum()
        stats['å¹³ç›˜å®¶æ•°'] = (df['pct_change'] == 0).sum()
        
        # æ¶¨è·Œåœï¼ˆç®€åŒ–åˆ¤æ–­ï¼šæ¶¨å¹…â‰¥9.9%ä¸ºæ¶¨åœï¼Œâ‰¤-9.9%ä¸ºè·Œåœï¼‰
        stats['æ¶¨åœå®¶æ•°'] = (df['pct_change'] >= 9.9).sum()
        stats['è·Œåœå®¶æ•°'] = (df['pct_change'] <= -9.9).sum()
        
        # å¤§æ¶¨å¤§è·Œï¼ˆæ¶¨è·Œå¹…â‰¥5%ï¼‰
        stats['å¤§æ¶¨å®¶æ•°_æ¶¨å¹…5%'] = (df['pct_change'] >= 5).sum()
        stats['å¤§è·Œå®¶æ•°_è·Œå¹…5%'] = (df['pct_change'] <= -5).sum()
        
        # å¸‚åœºå¹³å‡æ¶¨è·Œå¹…
        stats['å¸‚åœºå¹³å‡æ¶¨è·Œå¹…_%'] = df['pct_change'].mean()
        stats['å¸‚åœºæ¶¨è·Œå¹…ä¸­ä½æ•°_%'] = df['pct_change'].median()
        
        print(f"\nğŸ“Š æ¶¨è·Œç»Ÿè®¡:")
        print(f"  ä¸Šæ¶¨: {stats['ä¸Šæ¶¨å®¶æ•°']} åª ({stats['ä¸Šæ¶¨å®¶æ•°']/len(df)*100:.1f}%)")
        print(f"  ä¸‹è·Œ: {stats['ä¸‹è·Œå®¶æ•°']} åª ({stats['ä¸‹è·Œå®¶æ•°']/len(df)*100:.1f}%)")
        print(f"  å¹³ç›˜: {stats['å¹³ç›˜å®¶æ•°']} åª")
        print(f"  æ¶¨åœ: {stats['æ¶¨åœå®¶æ•°']} åª")
        print(f"  è·Œåœ: {stats['è·Œåœå®¶æ•°']} åª")
    
    # 2. æˆäº¤é‡å’Œæˆäº¤é¢ç»Ÿè®¡
    if 'volume' in df.columns:
        df['volume'] = pd.to_numeric(df['volume'], errors='coerce')
        stats['æˆäº¤é‡æ€»å’Œ_äº¿è‚¡'] = df['volume'].sum() / 100000000
        stats['æˆäº¤é‡å¹³å‡_ä¸‡è‚¡'] = df['volume'].mean() / 10000
        stats['æˆäº¤é‡ä¸­ä½æ•°_ä¸‡è‚¡'] = df['volume'].median() / 10000
        
        print(f"\nğŸ“ˆ æˆäº¤é‡:")
        print(f"  æ€»å’Œ: {stats['æˆäº¤é‡æ€»å’Œ_äº¿è‚¡']:.2f} äº¿è‚¡")
        print(f"  å¹³å‡: {stats['æˆäº¤é‡å¹³å‡_ä¸‡è‚¡']:.2f} ä¸‡è‚¡")
    
    if 'amount' in df.columns:
        df['amount'] = pd.to_numeric(df['amount'], errors='coerce')
        stats['æˆäº¤é¢æ€»å’Œ_äº¿å…ƒ'] = df['amount'].sum() / 100000000
        stats['æˆäº¤é¢å¹³å‡_äº¿å…ƒ'] = df['amount'].mean() / 100000000
        stats['æˆäº¤é¢ä¸­ä½æ•°_äº¿å…ƒ'] = df['amount'].median() / 100000000
        
        print(f"\nğŸ’° æˆäº¤é¢:")
        print(f"  æ€»å’Œ: {stats['æˆäº¤é¢æ€»å’Œ_äº¿å…ƒ']:.2f} äº¿å…ƒ")
        print(f"  å¹³å‡: {stats['æˆäº¤é¢å¹³å‡_äº¿å…ƒ']:.2f} äº¿å…ƒ")
    
    # 3. æ¢æ‰‹ç‡ç»Ÿè®¡
    if 'turnover' in df.columns:
        df['turnover'] = pd.to_numeric(df['turnover'], errors='coerce')
        stats['æ¢æ‰‹ç‡å¹³å‡_%'] = df['turnover'].mean()
        stats['æ¢æ‰‹ç‡ä¸­ä½æ•°_%'] = df['turnover'].median()
        
        # é«˜æ¢æ‰‹ç‡è‚¡ç¥¨æ•°é‡ï¼ˆæ¢æ‰‹ç‡>5%ï¼‰
        stats['é«˜æ¢æ‰‹ç‡å®¶æ•°_5%'] = (df['turnover'] > 5).sum()
        
        print(f"\nğŸ”„ æ¢æ‰‹ç‡:")
        print(f"  å¹³å‡: {stats['æ¢æ‰‹ç‡å¹³å‡_%']:.2f}%")
        print(f"  ä¸­ä½æ•°: {stats['æ¢æ‰‹ç‡ä¸­ä½æ•°_%']:.2f}%")
    
    # 4. RS Ratingåˆ†å¸ƒ
    if 'rs_rating' in df.columns:
        df['rs_rating'] = pd.to_numeric(df['rs_rating'], errors='coerce')
        
        stats['RS_Ratingå¹³å‡'] = df['rs_rating'].mean()
        stats['RS_Ratingä¸­ä½æ•°'] = df['rs_rating'].median()
        
        # RS Ratingåˆ†å¸ƒ
        stats['RSâ‰¥90_æ•°é‡'] = (df['rs_rating'] >= 90).sum()
        stats['RS_80-90_æ•°é‡'] = ((df['rs_rating'] >= 80) & (df['rs_rating'] < 90)).sum()
        stats['RS_70-80_æ•°é‡'] = ((df['rs_rating'] >= 70) & (df['rs_rating'] < 80)).sum()
        stats['RS_60-70_æ•°é‡'] = ((df['rs_rating'] >= 60) & (df['rs_rating'] < 70)).sum()
        stats['RS<60_æ•°é‡'] = (df['rs_rating'] < 60).sum()
        
        print(f"\nâ­ RS Ratingåˆ†å¸ƒ:")
        print(f"  â‰¥90: {stats['RSâ‰¥90_æ•°é‡']} åª")
        print(f"  80-90: {stats['RS_80-90_æ•°é‡']} åª")
        print(f"  70-80: {stats['RS_70-80_æ•°é‡']} åª")
        print(f"  60-70: {stats['RS_60-70_æ•°é‡']} åª")
        print(f"  <60: {stats['RS<60_æ•°é‡']} åª")
    
    # 5. ä»·æ ¼åŒºé—´ç»Ÿè®¡
    for ma in ['ma5', 'ma10', 'ma20', 'ma50', 'ma60', 'ma120']:
        if ma in df.columns and 'æ”¶ç›˜' in df.columns:
            close_col = 'æ”¶ç›˜' if 'æ”¶ç›˜' in df.columns else 'close'
            df[ma] = pd.to_numeric(df[ma], errors='coerce')
            df[close_col] = pd.to_numeric(df[close_col], errors='coerce')
            
            above_ma = (df[close_col] > df[ma]).sum()
            stats[f'ç«™ä¸Š{ma.upper()}_æ•°é‡'] = above_ma
            stats[f'ç«™ä¸Š{ma.upper()}_å æ¯”_%'] = above_ma / len(df) * 100
    
    # è½¬æ¢ä¸ºDataFrame
    df_stats = pd.DataFrame([stats])
    
    return df_stats


def save_daily_stats(df_new_stats):
    """ä¿å­˜æˆ–è¿½åŠ æ¯æ—¥å¸‚åœºç»Ÿè®¡"""
    
    stats_file = AGGREGATES_DIR / "daily_stats.parquet"
    
    if stats_file.exists():
        # è¯»å–å·²æœ‰æ•°æ®
        df_existing = pd.read_parquet(stats_file)
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ä»Šå¤©çš„æ•°æ®
        new_date = df_new_stats['æ—¥æœŸ'].iloc[0]
        
        if new_date in df_existing['æ—¥æœŸ'].values:
            # åˆ é™¤æ—§æ•°æ®
            df_existing = df_existing[df_existing['æ—¥æœŸ'] != new_date]
            logger.info(f"æ›´æ–°å·²æœ‰æ—¥æœŸçš„æ•°æ®: {new_date}")
        
        # è¿½åŠ æ–°æ•°æ®
        df_combined = pd.concat([df_existing, df_new_stats], ignore_index=True)
        
        # æŒ‰æ—¥æœŸæ’åº
        df_combined = df_combined.sort_values('æ—¥æœŸ')
        
    else:
        df_combined = df_new_stats
    
    # ä¿å­˜
    df_combined.to_parquet(stats_file, index=False)
    logger.info(f"âœ… å¸‚åœºç»Ÿè®¡å·²ä¿å­˜: {stats_file}")
    logger.info(f"  æ€»è®°å½•æ•°: {len(df_combined)}")
    
    return stats_file


# ============================================================
# 2. æ’åå†å²è¿½è¸ª
# ============================================================

def generate_ranking_history(snapshot_date=None):
    """
    ç”Ÿæˆæ’åå†å²
    
    è¿½è¸ªæŒ‡æ ‡ï¼š
    - RS Ratingæ’å
    - æ¶¨å¹…æ’å
    - æˆäº¤é‡æ’å
    """
    
    print("\n" + "=" * 80)
    print("  ç”Ÿæˆæ’åå†å²")
    print("=" * 80)
    
    # åŠ è½½å¿«ç…§
    snapshot_file = SNAPSHOT_DIR / "latest.parquet"
    if not snapshot_file.exists():
        if snapshot_date:
            snapshot_file = SNAPSHOT_DIR / f"snapshot_{snapshot_date}.parquet"
        
        if not snapshot_file.exists():
            print(f"âŒ æœªæ‰¾åˆ°å¿«ç…§æ–‡ä»¶: {snapshot_file}")
            return None
    
    print(f"è¯»å–å¿«ç…§: {snapshot_file.name}")
    df = pd.read_parquet(snapshot_file)
    
    if df.empty:
        print("âŒ å¿«ç…§æ•°æ®ä¸ºç©º")
        return None
    
    # æ ‡å‡†åŒ–åˆ—å
    rename_map = {
        'æ—¥æœŸ': 'date',
        'è‚¡ç¥¨ä»£ç ': 'symbol',
        'è‚¡ç¥¨åç§°': 'name',
        'æ¶¨è·Œå¹…': 'pct_change',
        'æˆäº¤é‡': 'volume',
    }
    df = df.rename(columns=rename_map)
    
    # è·å–æ—¥æœŸ
    if 'date' in df.columns:
        rank_date = df['date'].iloc[0]
        if isinstance(rank_date, str):
            rank_date = rank_date
        else:
            rank_date = rank_date.strftime('%Y-%m-%d')
    else:
        rank_date = datetime.now().strftime('%Y-%m-%d')
    
    print(f"æ’åæ—¥æœŸ: {rank_date}")
    
    # è®¡ç®—æ’å
    rankings = []
    
    for _, row in df.iterrows():
        rank_data = {
            'æ—¥æœŸ': rank_date,
            'symbol': row.get('symbol', ''),
            'name': row.get('name', ''),
        }
        
        # RS Ratingæ’å
        if 'rs_rating' in df.columns:
            rank_data['rs_rating'] = row.get('rs_rating', np.nan)
            rank_data['rs_rating_rank'] = (df['rs_rating'] >= row.get('rs_rating', 0)).sum()
        
        # æ¶¨å¹…æ’å
        if 'pct_change' in df.columns:
            rank_data['pct_change'] = row.get('pct_change', np.nan)
            rank_data['pct_change_rank'] = (df['pct_change'] >= row.get('pct_change', 0)).sum()
        
        # æˆäº¤é‡æ’å
        if 'volume' in df.columns:
            rank_data['volume'] = row.get('volume', np.nan)
            rank_data['volume_rank'] = (df['volume'] >= row.get('volume', 0)).sum()
        
        rankings.append(rank_data)
    
    df_rankings = pd.DataFrame(rankings)
    
    print(f"âœ“ ç”Ÿæˆæ’åæ•°æ®: {len(df_rankings)} æ¡")
    
    return df_rankings


def save_ranking_history(df_new_rankings):
    """ä¿å­˜æˆ–è¿½åŠ æ’åå†å²"""
    
    ranking_file = AGGREGATES_DIR / "ranking_history.parquet"
    
    if ranking_file.exists():
        # è¯»å–å·²æœ‰æ•°æ®
        df_existing = pd.read_parquet(ranking_file)
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰ä»Šå¤©çš„æ•°æ®
        new_date = df_new_rankings['æ—¥æœŸ'].iloc[0]
        
        if new_date in df_existing['æ—¥æœŸ'].values:
            # åˆ é™¤æ—§æ•°æ®
            df_existing = df_existing[df_existing['æ—¥æœŸ'] != new_date]
            logger.info(f"æ›´æ–°å·²æœ‰æ—¥æœŸçš„æ•°æ®: {new_date}")
        
        # è¿½åŠ æ–°æ•°æ®
        df_combined = pd.concat([df_existing, df_new_rankings], ignore_index=True)
        
        # æŒ‰æ—¥æœŸæ’åº
        df_combined = df_combined.sort_values(['æ—¥æœŸ', 'symbol'])
        
    else:
        df_combined = df_new_rankings
    
    # ä¿å­˜
    df_combined.to_parquet(ranking_file, index=False)
    logger.info(f"âœ… æ’åå†å²å·²ä¿å­˜: {ranking_file}")
    logger.info(f"  æ€»è®°å½•æ•°: {len(df_combined)}")
    
    return ranking_file


# ============================================================
# 3. æ¿å—è½®åŠ¨åˆ†æï¼ˆå¾…å®ç°ï¼‰
# ============================================================

def generate_sector_rotation():
    """
    ç”Ÿæˆæ¿å—è½®åŠ¨æ•°æ®
    
    TODO: éœ€è¦æ¿å—åˆ†ç±»æ•°æ®
    - æ¿å—å¹³å‡æ¶¨è·Œå¹…
    - æ¿å—èµ„é‡‘æµå…¥
    - æ¿å—ç›¸å¯¹å¼ºåº¦
    """
    print("\nâš ï¸  æ¿å—è½®åŠ¨åˆ†æåŠŸèƒ½å¾…å®ç°")
    print("   éœ€è¦å…ˆå»ºç«‹è‚¡ç¥¨-æ¿å—æ˜ å°„å…³ç³»")
    return None


# ============================================================
# ä¸»ç¨‹åº
# ============================================================

def main():
    print("=" * 80)
    print("  å¸‚åœºèšåˆæ•°æ®ç”Ÿæˆå™¨ v1.0")
    print("  - æ¯æ—¥å¸‚åœºç»Ÿè®¡")
    print("  - æ’åå†å²è¿½è¸ª")
    print("=" * 80)
    
    # æ£€æŸ¥å¿«ç…§ç›®å½•
    if not SNAPSHOT_DIR.exists():
        print(f"\nâŒ å¿«ç…§ç›®å½•ä¸å­˜åœ¨: {SNAPSHOT_DIR}")
        print(f"ğŸ’¡ è¯·å…ˆè¿è¡Œ generate_daily_snapshot.py ç”Ÿæˆå¿«ç…§")
        return
    
    # 1. ç”Ÿæˆæ¯æ—¥å¸‚åœºç»Ÿè®¡
    print("\n" + "=" * 80)
    print("ä»»åŠ¡1: æ¯æ—¥å¸‚åœºç»Ÿè®¡")
    print("=" * 80)
    
    df_stats = generate_daily_stats()
    
    if df_stats is not None:
        stats_file = save_daily_stats(df_stats)
    else:
        print("âŒ å¸‚åœºç»Ÿè®¡ç”Ÿæˆå¤±è´¥")
        stats_file = None
    
    # 2. ç”Ÿæˆæ’åå†å²
    print("\n" + "=" * 80)
    print("ä»»åŠ¡2: æ’åå†å²è¿½è¸ª")
    print("=" * 80)
    
    df_rankings = generate_ranking_history()
    
    if df_rankings is not None:
        ranking_file = save_ranking_history(df_rankings)
    else:
        print("âŒ æ’åå†å²ç”Ÿæˆå¤±è´¥")
        ranking_file = None
    
    # 3. æ¿å—è½®åŠ¨ï¼ˆå¾…å®ç°ï¼‰
    # generate_sector_rotation()
    
    # å®Œæˆ
    print("\n" + "=" * 80)
    print("âœ… å¸‚åœºèšåˆæ•°æ®ç”Ÿæˆå®Œæˆï¼")
    print("=" * 80)
    
    if stats_file:
        print(f"\nğŸ“Š å¸‚åœºç»Ÿè®¡: {stats_file}")
    if ranking_file:
        print(f"ğŸ“Š æ’åå†å²: {ranking_file}")
    
    print(f"\nğŸ’¡ æ•°æ®ç”¨é€”:")
    print(f"  - å¸‚åœºæƒ…ç»ªåˆ¤æ–­ï¼ˆæ‹©æ—¶å‚è€ƒï¼‰")
    print(f"  - è¿½è¸ªä¸ªè‚¡æ’åå˜åŒ–")
    print(f"  - åˆ†æå¸‚åœºæ•´ä½“è¶‹åŠ¿")
    
    print(f"\nğŸ“ˆ åç»­ä¼˜åŒ–:")
    print(f"  - æ·»åŠ æ¿å—è½®åŠ¨åˆ†æ")
    print(f"  - æ·»åŠ èµ„é‡‘æµå‘ç»Ÿè®¡")
    print(f"  - æ·»åŠ å¸‚åœºæƒ…ç»ªæŒ‡æ ‡")
    
    print("\n" + "=" * 80)


if __name__ == "__main__":
    main()
