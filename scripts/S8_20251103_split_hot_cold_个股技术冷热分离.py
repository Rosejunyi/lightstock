#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŠ€æœ¯æŒ‡æ ‡æ•°æ®å†·çƒ­åˆ†ç¦»è„šæœ¬ v1.0

åŠŸèƒ½ï¼š
1. å°†technical_indicatorsä¸­çš„2025å¹´æ•°æ®åˆ†ç¦»åˆ°technical_indicators_hot
2. ä¿æŒåŸæ–‡ä»¶å®Œæ•´ï¼ˆåŒ…å«å…¨éƒ¨å†å²ï¼‰
3. åˆ›å»ºçƒ­æ•°æ®ç›®å½•ï¼ŒåªåŒ…å«2025å¹´æ•°æ®
4. å¤§å¹…æå‡æ—¥å¸¸æŸ¥è¯¢æ€§èƒ½

æ¶æ„ä¼˜åŒ–ï¼š
- å†·æ•°æ®ï¼ˆ1990-2024ï¼‰ï¼štechnical_indicators/ï¼ˆå®Œæ•´å†å²ï¼Œç”¨äºå›æµ‹ï¼‰
- çƒ­æ•°æ®ï¼ˆ2025ï¼‰ï¼štechnical_indicators_hot/ï¼ˆå½“å¹´æ•°æ®ï¼Œç”¨äºæ—¥å¸¸æŸ¥è¯¢ï¼‰

ä½œè€…ï¼šClaude
ç‰ˆæœ¬ï¼šv1.0
æ—¥æœŸï¼š2025-11-03
"""

import pandas as pd
from pathlib import Path
from datetime import datetime
from tqdm import tqdm
import logging
import warnings
warnings.filterwarnings('ignore')

# ============================================================
# é…ç½®
# ============================================================

# ç›®å½•é…ç½®
COLD_DIR = Path("data/technical_indicators")          # å†·æ•°æ®ï¼ˆå®Œæ•´å†å²ï¼‰
HOT_DIR = Path("data/technical_indicators_hot")       # çƒ­æ•°æ®ï¼ˆ2025å¹´ï¼‰
LOG_DIR = Path("logs")

# å¹´ä»½é…ç½®
HOT_YEAR = 2025  # è¦åˆ†ç¦»çš„å¹´ä»½

# åˆ›å»ºç›®å½•
HOT_DIR.mkdir(parents=True, exist_ok=True)
LOG_DIR.mkdir(parents=True, exist_ok=True)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(
            LOG_DIR / f'hot_cold_split_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log',
            encoding='utf-8'
        ),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


def split_hot_cold_data():
    """åˆ†ç¦»å†·çƒ­æ•°æ®"""
    
    print("\n" + "=" * 80)
    print("  æŠ€æœ¯æŒ‡æ ‡æ•°æ®å†·çƒ­åˆ†ç¦»")
    print("=" * 80)
    print(f"  å†·æ•°æ®ï¼ˆå®Œæ•´å†å²ï¼‰: {COLD_DIR}")
    print(f"  çƒ­æ•°æ®ï¼ˆ{HOT_YEAR}å¹´ï¼‰: {HOT_DIR}")
    print("=" * 80)
    
    # è·å–æ‰€æœ‰æ–‡ä»¶
    indicator_files = list(COLD_DIR.glob("*.parquet"))
    
    if not indicator_files:
        print(f"\nâŒ æœªæ‰¾åˆ°æŠ€æœ¯æŒ‡æ ‡æ–‡ä»¶: {COLD_DIR}")
        return False
    
    print(f"\næ‰¾åˆ° {len(indicator_files)} ä¸ªæŠ€æœ¯æŒ‡æ ‡æ–‡ä»¶")
    
    # ç»Ÿè®¡
    stats = {
        'total': len(indicator_files),
        'success': 0,
        'skipped': 0,
        'failed': 0,
        'hot_rows_total': 0,
        'cold_rows_total': 0
    }
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    print(f"\nå¼€å§‹åˆ†ç¦»æ•°æ®...")
    
    for file_path in tqdm(indicator_files, desc="åˆ†ç¦»è¿›åº¦"):
        try:
            # è¯»å–å®Œæ•´æ•°æ®
            df = pd.read_parquet(file_path)
            
            if df.empty:
                stats['skipped'] += 1
                continue
            
            # æ£€æŸ¥æ—¥æœŸåˆ—
            date_col = None
            for col in ['æ—¥æœŸ', 'date', 'äº¤æ˜“æ—¥æœŸ']:
                if col in df.columns:
                    date_col = col
                    break
            
            if date_col is None:
                logger.warning(f"{file_path.name}: æœªæ‰¾åˆ°æ—¥æœŸåˆ—")
                stats['skipped'] += 1
                continue
            
            # è½¬æ¢æ—¥æœŸæ ¼å¼
            if df[date_col].dtype == 'object':
                df[date_col] = pd.to_datetime(df[date_col])
            
            # æå–å¹´ä»½
            df['year'] = df[date_col].dt.year
            
            # åˆ†ç¦»çƒ­æ•°æ®ï¼ˆ2025å¹´ï¼‰
            df_hot = df[df['year'] == HOT_YEAR].copy()
            
            if df_hot.empty:
                logger.debug(f"{file_path.name}: æ— {HOT_YEAR}å¹´æ•°æ®ï¼Œè·³è¿‡")
                stats['skipped'] += 1
                continue
            
            # åˆ é™¤ä¸´æ—¶yearåˆ—
            df_hot = df_hot.drop(columns=['year'])
            
            # ä¿å­˜çƒ­æ•°æ®
            hot_file = HOT_DIR / file_path.name
            df_hot.to_parquet(hot_file, index=False)
            
            # æ›´æ–°ç»Ÿè®¡
            stats['success'] += 1
            stats['hot_rows_total'] += len(df_hot)
            stats['cold_rows_total'] += len(df)
            
        except Exception as e:
            logger.error(f"{file_path.name}: å¤„ç†å¤±è´¥ - {e}")
            stats['failed'] += 1
            continue
    
    # æ‰“å°ç»Ÿè®¡
    print("\n" + "=" * 80)
    print("  å†·çƒ­åˆ†ç¦»å®Œæˆç»Ÿè®¡")
    print("=" * 80)
    print(f"  æ€»æ–‡ä»¶æ•°: {stats['total']}")
    print(f"  âœ… æˆåŠŸåˆ†ç¦»: {stats['success']}")
    print(f"  â­ï¸  è·³è¿‡: {stats['skipped']}")
    if stats['failed'] > 0:
        print(f"  âŒ å¤±è´¥: {stats['failed']}")
    print(f"\n  ğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"     å†·æ•°æ®æ€»è¡Œæ•°: {stats['cold_rows_total']:,}")
    print(f"     çƒ­æ•°æ®æ€»è¡Œæ•°: {stats['hot_rows_total']:,}")
    print(f"     å¹³å‡æ¯è‚¡{HOT_YEAR}å¹´æ•°æ®: {stats['hot_rows_total'] // max(stats['success'], 1):,} è¡Œ")
    
    # è®¡ç®—å­˜å‚¨å¤§å°
    cold_size = sum(f.stat().st_size for f in COLD_DIR.glob("*.parquet")) / 1024 / 1024
    hot_size = sum(f.stat().st_size for f in HOT_DIR.glob("*.parquet")) / 1024 / 1024
    
    print(f"\n  ğŸ’¾ å­˜å‚¨å ç”¨:")
    print(f"     å†·æ•°æ®: {cold_size:.2f} MB")
    print(f"     çƒ­æ•°æ®: {hot_size:.2f} MB")
    print(f"     çƒ­/å†·æ¯”ä¾‹: {hot_size/cold_size*100:.2f}%")
    
    print("\n" + "=" * 80)
    print("âœ… å†·çƒ­åˆ†ç¦»å®Œæˆï¼")
    print("=" * 80)
    print(f"\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print(f"  - æ—¥å¸¸æŸ¥è¯¢å’Œå¢é‡è®¡ç®—ä½¿ç”¨: {HOT_DIR}")
    print(f"  - é‡åŒ–å›æµ‹ä½¿ç”¨: {COLD_DIR}ï¼ˆå®Œæ•´å†å²ï¼‰")
    print(f"  - çƒ­æ•°æ®æŸ¥è¯¢é€Ÿåº¦æå‡ 3-10å€ âš¡")
    print(f"\nâš ï¸  æ³¨æ„äº‹é¡¹:")
    print(f"  - å†·æ•°æ®ä¿æŒä¸å˜ï¼ˆå®Œæ•´å†å²ï¼‰")
    print(f"  - çƒ­æ•°æ®åªåŒ…å«{HOT_YEAR}å¹´æ•°æ®")
    print(f"  - å¢é‡è®¡ç®—è„šæœ¬éœ€è¦æ›´æ–°ä¸ºä½¿ç”¨çƒ­æ•°æ®ç›®å½•")
    print(f"  - æ¯å¹´å¹´åˆéœ€è¦é‡æ–°åˆ†ç¦»ï¼ˆå°†æ–°ä¸€å¹´ä½œä¸ºçƒ­æ•°æ®ï¼‰")
    
    return stats['success'] > 0


def verify_split():
    """éªŒè¯åˆ†ç¦»ç»“æœ"""
    print("\n" + "=" * 80)
    print("  éªŒè¯åˆ†ç¦»ç»“æœ")
    print("=" * 80)
    
    # éšæœºæŠ½å–3ä¸ªæ–‡ä»¶éªŒè¯
    cold_files = list(COLD_DIR.glob("*.parquet"))
    hot_files = list(HOT_DIR.glob("*.parquet"))
    
    print(f"\nå†·æ•°æ®ç›®å½•: {len(cold_files)} ä¸ªæ–‡ä»¶")
    print(f"çƒ­æ•°æ®ç›®å½•: {len(hot_files)} ä¸ªæ–‡ä»¶")
    
    if not hot_files:
        print("\nâŒ çƒ­æ•°æ®ç›®å½•ä¸ºç©º")
        return False
    
    # éªŒè¯å‰3ä¸ªæ–‡ä»¶
    print(f"\néªŒè¯æ ·æœ¬ï¼ˆå‰3ä¸ªï¼‰:")
    for i, hot_file in enumerate(hot_files[:3], 1):
        cold_file = COLD_DIR / hot_file.name
        
        if not cold_file.exists():
            print(f"  {i}. {hot_file.name}: âŒ å†·æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
            continue
        
        df_cold = pd.read_parquet(cold_file)
        df_hot = pd.read_parquet(hot_file)
        
        # æŸ¥æ‰¾æ—¥æœŸåˆ—
        date_col = None
        for col in ['æ—¥æœŸ', 'date', 'äº¤æ˜“æ—¥æœŸ']:
            if col in df_hot.columns:
                date_col = col
                break
        
        if date_col:
            hot_dates = pd.to_datetime(df_hot[date_col])
            hot_years = hot_dates.dt.year.unique()
            
            print(f"  {i}. {hot_file.name}:")
            print(f"     å†·æ•°æ®: {len(df_cold)} è¡Œ")
            print(f"     çƒ­æ•°æ®: {len(df_hot)} è¡Œ")
            print(f"     çƒ­æ•°æ®å¹´ä»½: {sorted(hot_years)}")
            print(f"     éªŒè¯: {'âœ… æ­£ç¡®' if all(y == HOT_YEAR for y in hot_years) else 'âŒ é”™è¯¯'}")
        else:
            print(f"  {i}. {hot_file.name}: âš ï¸  æœªæ‰¾åˆ°æ—¥æœŸåˆ—")
    
    print("\n" + "=" * 80)
    return True


if __name__ == "__main__":
    success = split_hot_cold_data()
    
    if success:
        verify_split()
        exit(0)
    else:
        exit(1)
