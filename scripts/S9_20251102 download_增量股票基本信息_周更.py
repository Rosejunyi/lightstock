#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸‹è½½è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ v4.0 - å¢é‡æ›´æ–°ç‰ˆ

æ–°å¢åŠŸèƒ½ï¼š
1. âœ… æ™ºèƒ½æ£€æµ‹ï¼šæ£€æŸ¥ç°æœ‰æ•°æ®çš„æ›´æ–°æ—¶é—´
2. âœ… å¢é‡æ›´æ–°ï¼šåªæ›´æ–°æ–°å¢/å˜åŒ–çš„è‚¡ç¥¨
3. âœ… å†å²å¤‡ä»½ï¼šä¿ç•™ä¸Šä¸€ç‰ˆæœ¬æ•°æ®
4. âœ… å¯¹æ¯”æŠ¥å‘Šï¼šæ˜¾ç¤ºæ–°å¢ã€é€€å¸‚ã€å˜åŒ–çš„è‚¡ç¥¨

é€‚ç”¨åœºæ™¯ï¼š
- å®šæœŸç»´æŠ¤è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆå»ºè®®æ¯æœˆè¿è¡Œä¸€æ¬¡ï¼‰
- è‡ªåŠ¨è·³è¿‡ä¸éœ€è¦æ›´æ–°çš„æƒ…å†µ
- ä¿ç•™å†å²ç‰ˆæœ¬ä¾¿äºè¿½æº¯

ä½œè€…ï¼šClaude
ç‰ˆæœ¬ï¼šv4.0
æ—¥æœŸï¼š2025-11-02
"""

import baostock as bs
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
from tqdm import tqdm
import logging
import time
import shutil

# å°è¯•å¯¼å…¥ akshare
try:
    import akshare as ak
    HAS_AKSHARE = True
except ImportError:
    HAS_AKSHARE = False

# ============================================================
# é…ç½®
# ============================================================

OUTPUT_FILE = Path("data/stock_basic_info.parquet")
BACKUP_DIR = Path("data/backups/stock_basic_info")
LOG_DIR = Path("logs")

# æ›´æ–°ç­–ç•¥é…ç½®
UPDATE_CONFIG = {
    'force_update': False,           # æ˜¯å¦å¼ºåˆ¶æ›´æ–°ï¼ˆå¿½ç•¥æ—¶é—´æ£€æŸ¥ï¼‰
    'update_interval_days': 7,       # æ›´æ–°é—´éš”ï¼ˆå¤©ï¼‰ï¼šè·ç¦»ä¸Šæ¬¡æ›´æ–°è¶…è¿‡Nå¤©æ‰æ›´æ–°
    'keep_backups': 5,               # ä¿ç•™æœ€è¿‘Nä¸ªå¤‡ä»½
}

MAX_RETRIES = 3
RETRY_DELAY = 2

# åˆ›å»ºç›®å½•
OUTPUT_FILE.parent.mkdir(parents=True, exist_ok=True)
BACKUP_DIR.mkdir(parents=True, exist_ok=True)
LOG_DIR.mkdir(parents=True, exist_ok=True)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(
            LOG_DIR / f'stock_info_incremental_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log',
            encoding='utf-8'
        ),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ============================================================
# å·¥å…·å‡½æ•°
# ============================================================

def check_need_update():
    """
    æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
    
    è¿”å›: (éœ€è¦æ›´æ–°, åŸå› , ç°æœ‰æ•°æ®)
    """
    if UPDATE_CONFIG['force_update']:
        return True, "å¼ºåˆ¶æ›´æ–°æ¨¡å¼", None
    
    if not OUTPUT_FILE.exists():
        return True, "é¦–æ¬¡è¿è¡Œï¼Œæ— å†å²æ•°æ®", None
    
    try:
        # è¯»å–ç°æœ‰æ•°æ®
        df_existing = pd.read_parquet(OUTPUT_FILE)
        
        if df_existing.empty:
            return True, "ç°æœ‰æ•°æ®ä¸ºç©º", None
        
        # æ£€æŸ¥æ›´æ–°æ—¶é—´
        if 'æ›´æ–°æ—¶é—´' in df_existing.columns:
            last_update = df_existing['æ›´æ–°æ—¶é—´'].iloc[0]
            last_update_dt = pd.to_datetime(last_update)
            days_since_update = (datetime.now() - last_update_dt).days
            
            if days_since_update < UPDATE_CONFIG['update_interval_days']:
                return False, f"è·ç¦»ä¸Šæ¬¡æ›´æ–°ä»…{days_since_update}å¤©ï¼Œæ— éœ€æ›´æ–°", df_existing
            else:
                return True, f"è·ç¦»ä¸Šæ¬¡æ›´æ–°å·²{days_since_update}å¤©", df_existing
        else:
            return True, "æ— æ›´æ–°æ—¶é—´ä¿¡æ¯", df_existing
    
    except Exception as e:
        logger.warning(f"è¯»å–ç°æœ‰æ•°æ®å¤±è´¥: {e}")
        return True, "è¯»å–ç°æœ‰æ•°æ®å¤±è´¥", None

def backup_existing_data():
    """å¤‡ä»½ç°æœ‰æ•°æ®"""
    if not OUTPUT_FILE.exists():
        return None
    
    try:
        # ç”Ÿæˆå¤‡ä»½æ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_file = BACKUP_DIR / f"stock_basic_info_{timestamp}.parquet"
        
        # å¤åˆ¶æ–‡ä»¶
        shutil.copy2(OUTPUT_FILE, backup_file)
        logger.info(f"âœ… å·²å¤‡ä»½åˆ°: {backup_file}")
        
        # æ¸…ç†æ—§å¤‡ä»½
        cleanup_old_backups()
        
        return backup_file
    
    except Exception as e:
        logger.error(f"å¤‡ä»½å¤±è´¥: {e}")
        return None

def cleanup_old_backups():
    """æ¸…ç†æ—§å¤‡ä»½ï¼Œåªä¿ç•™æœ€è¿‘Nä¸ª"""
    try:
        backups = sorted(BACKUP_DIR.glob("stock_basic_info_*.parquet"), reverse=True)
        
        if len(backups) > UPDATE_CONFIG['keep_backups']:
            for old_backup in backups[UPDATE_CONFIG['keep_backups']:]:
                old_backup.unlink()
                logger.info(f"åˆ é™¤æ—§å¤‡ä»½: {old_backup.name}")
    
    except Exception as e:
        logger.warning(f"æ¸…ç†æ—§å¤‡ä»½å¤±è´¥: {e}")

def get_stock_list():
    """è·å–æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨"""
    logger.info("è·å–è‚¡ç¥¨åˆ—è¡¨...")
    
    all_stocks = []
    rs = bs.query_stock_basic()
    if rs.error_code == '0':
        while (rs.error_code == '0') & rs.next():
            all_stocks.append(rs.get_row_data())
    
    if not all_stocks:
        logger.error("âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥")
        return None
    
    df = pd.DataFrame(all_stocks, columns=rs.fields)
    df = df[df['code'].str.startswith(('sh.6', 'sz.0', 'sz.3'))]
    logger.info(f"âœ… è·å–åˆ° {len(df)} åªè‚¡ç¥¨")
    
    return df

def get_stock_industry(stock_code, retry_count=0):
    """è·å–è‚¡ç¥¨çš„è¡Œä¸šåˆ†ç±»"""
    try:
        rs = bs.query_stock_industry(code=stock_code)
        
        if rs.error_code != '0':
            if retry_count < MAX_RETRIES:
                time.sleep(RETRY_DELAY)
                return get_stock_industry(stock_code, retry_count + 1)
            return None
        
        industry_list = []
        while (rs.error_code == '0') & rs.next():
            row_data = rs.get_row_data()
            industry_list.append(row_data)
        
        if not industry_list:
            return None
        
        return industry_list[0]
    
    except Exception as e:
        logger.warning(f"{stock_code}: è·å–è¡Œä¸šå¤±è´¥ - {e}")
        return None

def get_all_stock_shares_akshare():
    """ä½¿ç”¨ AKShare æ‰¹é‡è·å–æ‰€æœ‰è‚¡ç¥¨çš„è‚¡æœ¬æ•°æ®"""
    if not HAS_AKSHARE:
        logger.warning("æœªå®‰è£… akshareï¼Œè·³è¿‡è‚¡æœ¬æ•°æ®è·å–")
        return {}
    
    try:
        logger.info("æ­£åœ¨ä» AKShare æ‰¹é‡è·å–è‚¡æœ¬æ•°æ®...")
        
        df_spot = ak.stock_zh_a_spot_em()
        
        shares_dict = {}
        for _, row in df_spot.iterrows():
            code = row['ä»£ç ']
            price = row.get('æœ€æ–°ä»·', None)
            total_mv = row.get('æ€»å¸‚å€¼', None)
            float_mv = row.get('æµé€šå¸‚å€¼', None)
            
            if price and total_mv and price > 0:
                total_shares = total_mv / price / 10000
                float_shares = float_mv / price / 10000 if float_mv and float_mv > 0 else None
                
                shares_dict[code] = {
                    'æ€»è‚¡æœ¬': round(total_shares, 2),
                    'æµé€šè‚¡æœ¬': round(float_shares, 2) if float_shares else None
                }
        
        logger.info(f"âœ… è·å–åˆ° {len(shares_dict)} åªè‚¡ç¥¨çš„è‚¡æœ¬æ•°æ®")
        return shares_dict
    
    except Exception as e:
        logger.error(f"ä» AKShare è·å–è‚¡æœ¬æ•°æ®å¤±è´¥: {e}")
        return {}

def compare_with_existing(df_new, df_old):
    """
    å¯¹æ¯”æ–°æ—§æ•°æ®ï¼Œç”Ÿæˆå˜åŒ–æŠ¥å‘Š
    
    è¿”å›: æ–°å¢è‚¡ç¥¨, é€€å¸‚è‚¡ç¥¨, å˜åŒ–è‚¡ç¥¨
    """
    if df_old is None or df_old.empty:
        return df_new, pd.DataFrame(), pd.DataFrame()
    
    # è·å–è‚¡ç¥¨ä»£ç é›†åˆ
    codes_new = set(df_new['è‚¡ç¥¨ä»£ç '])
    codes_old = set(df_old['è‚¡ç¥¨ä»£ç '])
    
    # æ–°å¢è‚¡ç¥¨
    new_codes = codes_new - codes_old
    df_new_stocks = df_new[df_new['è‚¡ç¥¨ä»£ç '].isin(new_codes)]
    
    # é€€å¸‚è‚¡ç¥¨
    delisted_codes = codes_old - codes_new
    df_delisted = df_old[df_old['è‚¡ç¥¨ä»£ç '].isin(delisted_codes)]
    
    # å˜åŒ–è‚¡ç¥¨ï¼ˆè¡Œä¸šæˆ–å…¶ä»–ä¿¡æ¯å˜åŒ–ï¼‰
    common_codes = codes_new & codes_old
    changes = []
    
    for code in common_codes:
        row_new = df_new[df_new['è‚¡ç¥¨ä»£ç '] == code].iloc[0]
        row_old = df_old[df_old['è‚¡ç¥¨ä»£ç '] == code].iloc[0]
        
        # æ£€æŸ¥å…³é”®å­—æ®µæ˜¯å¦å˜åŒ–
        if row_new['è¡Œä¸š'] != row_old['è¡Œä¸š']:
            changes.append({
                'è‚¡ç¥¨ä»£ç ': code,
                'è‚¡ç¥¨åç§°': row_new['è‚¡ç¥¨åç§°'],
                'å˜åŒ–ç±»å‹': 'è¡Œä¸šå˜æ›´',
                'æ—§å€¼': row_old['è¡Œä¸š'],
                'æ–°å€¼': row_new['è¡Œä¸š']
            })
    
    df_changes = pd.DataFrame(changes)
    
    return df_new_stocks, df_delisted, df_changes

def incremental_update(df_new, df_old):
    """
    å¢é‡æ›´æ–°ï¼šåˆå¹¶æ–°æ—§æ•°æ®
    
    ç­–ç•¥ï¼š
    1. ä¿ç•™æ—§æ•°æ®ä¸­çš„å†å²è®°å½•
    2. æ›´æ–°å…±åŒè‚¡ç¥¨çš„ä¿¡æ¯
    3. æ·»åŠ æ–°å¢è‚¡ç¥¨
    4. æ ‡è®°é€€å¸‚è‚¡ç¥¨ï¼ˆä½†ä¸åˆ é™¤ï¼‰
    """
    if df_old is None or df_old.empty:
        return df_new
    
    # è·å–è‚¡ç¥¨ä»£ç é›†åˆ
    codes_new = set(df_new['è‚¡ç¥¨ä»£ç '])
    codes_old = set(df_old['è‚¡ç¥¨ä»£ç '])
    
    # 1. æ›´æ–°å…±åŒè‚¡ç¥¨ï¼ˆä½¿ç”¨æ–°æ•°æ®ï¼‰
    common_codes = codes_new & codes_old
    df_updated = df_new[df_new['è‚¡ç¥¨ä»£ç '].isin(common_codes)]
    
    # 2. æ·»åŠ æ–°å¢è‚¡ç¥¨
    new_codes = codes_new - codes_old
    df_new_stocks = df_new[df_new['è‚¡ç¥¨ä»£ç '].isin(new_codes)]
    
    # 3. ä¿ç•™é€€å¸‚è‚¡ç¥¨ï¼ˆæ ‡è®°ï¼‰
    delisted_codes = codes_old - codes_new
    df_delisted = df_old[df_old['è‚¡ç¥¨ä»£ç '].isin(delisted_codes)].copy()
    if not df_delisted.empty:
        df_delisted['çŠ¶æ€'] = 'å·²é€€å¸‚'
        df_delisted['æ›´æ–°æ—¶é—´'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    # åˆå¹¶
    df_result = pd.concat([df_updated, df_new_stocks, df_delisted], ignore_index=True)
    
    # æ’åº
    df_result = df_result.sort_values('è‚¡ç¥¨ä»£ç ').reset_index(drop=True)
    
    return df_result

# ============================================================
# ä¸»ç¨‹åº
# ============================================================

def main():
    print("=" * 80)
    print("  ä¸‹è½½è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ v4.0 - å¢é‡æ›´æ–°ç‰ˆ")
    print("  æ™ºèƒ½æ£€æµ‹ + è‡ªåŠ¨å¤‡ä»½ + å˜åŒ–æŠ¥å‘Š")
    print("=" * 80)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
    need_update, reason, df_existing = check_need_update()
    
    print(f"\nğŸ“Š æ›´æ–°æ£€æŸ¥:")
    print(f"  çŠ¶æ€: {'éœ€è¦æ›´æ–°' if need_update else 'æ— éœ€æ›´æ–°'}")
    print(f"  åŸå› : {reason}")
    
    if df_existing is not None:
        last_update = df_existing['æ›´æ–°æ—¶é—´'].iloc[0] if 'æ›´æ–°æ—¶é—´' in df_existing.columns else 'æœªçŸ¥'
        print(f"  ä¸Šæ¬¡æ›´æ–°: {last_update}")
        print(f"  ç°æœ‰è‚¡ç¥¨æ•°: {len(df_existing)}")
    
    if not need_update:
        print(f"\nğŸ’¡ æç¤º:")
        print(f"  - å¦‚éœ€å¼ºåˆ¶æ›´æ–°ï¼Œè¯·ä¿®æ”¹é…ç½®ï¼šUPDATE_CONFIG['force_update'] = True")
        print(f"  - æˆ–ä¿®æ”¹æ›´æ–°é—´éš”ï¼šUPDATE_CONFIG['update_interval_days'] = N")
        return
    
    # ç”¨æˆ·ç¡®è®¤
    print(f"\nâš ï¸  å³å°†å¼€å§‹æ›´æ–°...")
    if df_existing is not None:
        response = input("æ˜¯å¦ç»§ç»­ï¼Ÿ(y/n): ")
        if response.lower() != 'y':
            print("å·²å–æ¶ˆæ›´æ–°")
            return
    
    # å¤‡ä»½ç°æœ‰æ•°æ®
    if df_existing is not None:
        print(f"\nğŸ“¦ å¤‡ä»½ç°æœ‰æ•°æ®...")
        backup_file = backup_existing_data()
        if backup_file:
            print(f"  âœ… å¤‡ä»½æˆåŠŸ")
    
    # æ£€æŸ¥ AKShare
    if not HAS_AKSHARE:
        print("\nâš ï¸  æœªå®‰è£… akshareï¼Œå°†æ— æ³•è·å–è‚¡æœ¬æ•°æ®")
    
    # ç™»å½• Baostock
    print("\nç™»å½• Baostock...")
    lg = bs.login()
    if lg.error_code != '0':
        print(f"âŒ ç™»å½•å¤±è´¥: {lg.error_msg}")
        return
    
    print("âœ… ç™»å½•æˆåŠŸ")
    
    # è·å–è‚¡ç¥¨åˆ—è¡¨
    stock_list_df = get_stock_list()
    if stock_list_df is None or stock_list_df.empty:
        print("âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥")
        bs.logout()
        return
    
    # æ‰¹é‡è·å–è‚¡æœ¬æ•°æ®
    shares_dict = get_all_stock_shares_akshare() if HAS_AKSHARE else {}
    
    # æ”¶é›†è‚¡ç¥¨ä¿¡æ¯
    stock_info_list = []
    
    print("\nå¼€å§‹æ•´ç†è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯...\n")
    
    for idx, row in tqdm(stock_list_df.iterrows(), total=len(stock_list_df), desc="å¤„ç†è¿›åº¦"):
        stock_code_full = row['code']
        stock_code_pure = stock_code_full.split('.')[1]
        stock_name = row.get('code_name', '')
        
        # åŸºæœ¬ä¿¡æ¯
        info = {
            'è‚¡ç¥¨ä»£ç ': stock_code_pure,
            'è‚¡ç¥¨åç§°': stock_name,
            'å¸‚åœº': stock_code_full.split('.')[0],
            'ä¸Šå¸‚æ—¥æœŸ': row.get('ipoDate', ''),
            'é€€å¸‚æ—¥æœŸ': row.get('outDate', ''),
            'è‚¡ç¥¨ç±»å‹': row.get('type', ''),
            'çŠ¶æ€': row.get('status', ''),
        }
        
        # è·å–è¡Œä¸šä¿¡æ¯
        industry_info = get_stock_industry(stock_code_full)
        if industry_info and len(industry_info) >= 5:
            info['è¡Œä¸š'] = industry_info[3] if industry_info[3] else ''
            info['è¡Œä¸šåˆ†ç±»'] = industry_info[4] if industry_info[4] else ''
        else:
            info['è¡Œä¸š'] = ''
            info['è¡Œä¸šåˆ†ç±»'] = ''
        
        # è·å–è‚¡æœ¬ä¿¡æ¯
        if shares_dict and stock_code_pure in shares_dict:
            info['æ€»è‚¡æœ¬'] = shares_dict[stock_code_pure]['æ€»è‚¡æœ¬']
            info['æµé€šè‚¡æœ¬'] = shares_dict[stock_code_pure]['æµé€šè‚¡æœ¬']
        else:
            info['æ€»è‚¡æœ¬'] = None
            info['æµé€šè‚¡æœ¬'] = None
        
        # æ·»åŠ æ›´æ–°æ—¶é—´
        info['æ›´æ–°æ—¶é—´'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        stock_info_list.append(info)
        
        if (idx + 1) % 100 == 0:
            time.sleep(0.5)
    
    bs.logout()
    
    # è½¬æ¢ä¸º DataFrame
    df_new = pd.DataFrame(stock_info_list)
    
    # æ•°æ®ç±»å‹è½¬æ¢
    for col in ['æ€»è‚¡æœ¬', 'æµé€šè‚¡æœ¬']:
        if col in df_new.columns:
            df_new[col] = pd.to_numeric(df_new[col], errors='coerce')
    
    # å¯¹æ¯”åˆ†æ
    if df_existing is not None:
        print("\n" + "=" * 80)
        print("å˜åŒ–åˆ†æ")
        print("=" * 80)
        
        df_new_stocks, df_delisted, df_changes = compare_with_existing(df_new, df_existing)
        
        print(f"ğŸ“ˆ æ–°å¢è‚¡ç¥¨: {len(df_new_stocks)} åª")
        if not df_new_stocks.empty:
            print("\næ–°å¢è‚¡ç¥¨åˆ—è¡¨:")
            for _, row in df_new_stocks.head(10).iterrows():
                print(f"  - {row['è‚¡ç¥¨ä»£ç ']} {row['è‚¡ç¥¨åç§°']} ({row['è¡Œä¸š']})")
            if len(df_new_stocks) > 10:
                print(f"  ... è¿˜æœ‰ {len(df_new_stocks) - 10} åª")
        
        print(f"\nğŸ“‰ é€€å¸‚è‚¡ç¥¨: {len(df_delisted)} åª")
        if not df_delisted.empty:
            print("\né€€å¸‚è‚¡ç¥¨åˆ—è¡¨:")
            for _, row in df_delisted.head(10).iterrows():
                print(f"  - {row['è‚¡ç¥¨ä»£ç ']} {row['è‚¡ç¥¨åç§°']}")
        
        print(f"\nğŸ”„ ä¿¡æ¯å˜åŒ–: {len(df_changes)} åª")
        if not df_changes.empty:
            print("\nå˜åŒ–è¯¦æƒ…:")
            for _, row in df_changes.head(10).iterrows():
                print(f"  - {row['è‚¡ç¥¨ä»£ç ']} {row['è‚¡ç¥¨åç§°']}: {row['å˜åŒ–ç±»å‹']}")
                print(f"    {row['æ—§å€¼']} â†’ {row['æ–°å€¼']}")
        
        # å¢é‡æ›´æ–°
        df_final = incremental_update(df_new, df_existing)
        print(f"\nâœ… å¢é‡æ›´æ–°å®Œæˆ:")
        print(f"  åŸæœ‰: {len(df_existing)} åª")
        print(f"  æ›´æ–°å: {len(df_final)} åª")
    else:
        df_final = df_new
        print(f"\nâœ… é¦–æ¬¡ä¸‹è½½å®Œæˆ: {len(df_final)} åª")
    
    # ä¿å­˜
    df_final.to_parquet(OUTPUT_FILE, index=False)
    csv_file = OUTPUT_FILE.parent / 'stock_basic_info.csv'
    df_final.to_csv(csv_file, index=False, encoding='utf-8-sig')
    
    # è¾“å‡ºç»Ÿè®¡
    print("\n" + "=" * 80)
    print("âœ… æ›´æ–°å®Œæˆ")
    print("=" * 80)
    print(f"æ€»è‚¡ç¥¨æ•°: {len(df_final)}")
    print(f"æœ‰è¡Œä¸šä¿¡æ¯: {df_final['è¡Œä¸š'].notna().sum()} ({df_final['è¡Œä¸š'].notna().sum()/len(df_final)*100:.1f}%)")
    print(f"æœ‰æ€»è‚¡æœ¬: {df_final['æ€»è‚¡æœ¬'].notna().sum()} ({df_final['æ€»è‚¡æœ¬'].notna().sum()/len(df_final)*100:.1f}%)")
    print(f"æœ‰æµé€šè‚¡æœ¬: {df_final['æµé€šè‚¡æœ¬'].notna().sum()} ({df_final['æµé€šè‚¡æœ¬'].notna().sum()/len(df_final)*100:.1f}%)")
    print("=" * 80)
    
    # æ˜¾ç¤ºæ•°æ®ç¤ºä¾‹
    print("\nğŸ“Š æ•°æ®ç¤ºä¾‹:")
    display_cols = ['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'è¡Œä¸š', 'æ€»è‚¡æœ¬', 'æµé€šè‚¡æœ¬', 'çŠ¶æ€']
    available_cols = [col for col in display_cols if col in df_final.columns]
    print(df_final[available_cols].head(10).to_string(index=False))
    
    print(f"\nğŸ’¡ æ•°æ®å·²ä¿å­˜è‡³: {OUTPUT_FILE}")
    print(f"ğŸ’¡ å¤‡ä»½ç›®å½•: {BACKUP_DIR}")

if __name__ == "__main__":
    main()
