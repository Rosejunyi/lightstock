# scripts/calculate_indicators.py (å®Œæ•´Pythonå®ç°ç‰ˆ)
import os
import sys
from supabase import create_client, Client
from datetime import datetime, timedelta
from dotenv import load_dotenv
import pandas as pd
import numpy as np

load_dotenv()
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")

def get_latest_trading_date(supabase: Client) -> str:
    """è·å–æœ€æ–°äº¤æ˜“æ—¥"""
    response = supabase.table('daily_bars').select('date').order('date', desc=True).limit(1).execute()
    if response.data:
        return response.data[0]['date']
    return (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')

def fetch_historical_bars(supabase: Client, days_back: int, target_date: str):
    """è·å–å†å²Kçº¿æ•°æ®"""
    start_date = (datetime.strptime(target_date, '%Y-%m-%d') - timedelta(days=days_back * 2)).strftime('%Y-%m-%d')
    
    print(f"  -> Fetching bars from {start_date} to {target_date}...")
    all_data = []
    offset = 0
    batch_size = 1000
    
    while True:
        response = supabase.table('daily_bars')\
            .select('symbol, date, close, volume, high, low')\
            .gte('date', start_date)\
            .lte('date', target_date)\
            .order('symbol')\
            .order('date')\
            .range(offset, offset + batch_size - 1)\
            .execute()
        
        if not response.data:
            break
        
        all_data.extend(response.data)
        offset += batch_size
        
        if len(response.data) < batch_size:
            break
    
    print(f"  -> Fetched {len(all_data)} records")
    return pd.DataFrame(all_data)

def calculate_moving_averages(df: pd.DataFrame, periods: list) -> pd.DataFrame:
    """è®¡ç®—ç§»åŠ¨å¹³å‡çº¿"""
    print("  -> Calculating moving averages...")
    
    # æŒ‰è‚¡ç¥¨åˆ†ç»„ï¼Œè®¡ç®—æ¯ä¸ªå‘¨æœŸçš„MA
    for period in periods:
        df[f'ma{period}'] = df.groupby('symbol')['close'].transform(
            lambda x: x.rolling(window=period, min_periods=period).mean()
        )
    
    return df

def calculate_52w_high_low(df: pd.DataFrame, window: int = 200) -> pd.DataFrame:
    """è®¡ç®—52å‘¨ï¼ˆ200ä¸ªäº¤æ˜“æ—¥ï¼‰é«˜ä½ç‚¹"""
    print("  -> Calculating 52-week high/low...")
    
    df['high_52w'] = df.groupby('symbol')['high'].transform(
        lambda x: x.rolling(window=window, min_periods=window).max()
    )
    df['low_52w'] = df.groupby('symbol')['low'].transform(
        lambda x: x.rolling(window=window, min_periods=window).min()
    )
    
    return df

def calculate_volume_ma(df: pd.DataFrame, periods: list) -> pd.DataFrame:
    """è®¡ç®—æˆäº¤é‡å‡çº¿"""
    print("  -> Calculating volume moving averages...")
    
    for period in periods:
        df[f'volume_ma{period}'] = df.groupby('symbol')['volume'].transform(
            lambda x: x.rolling(window=period, min_periods=period).mean()
        )
    
    return df

def calculate_rs_rating_python(df: pd.DataFrame, lookback_period: int = 60) -> pd.DataFrame:
    """
    è®¡ç®—RS Ratingï¼ˆç›¸å¯¹å¼ºåº¦è¯„çº§ï¼‰
    
    ç¬¬ä¸€æ€§åŸç†ï¼š
    1. è®¡ç®—æ¯åªè‚¡ç¥¨åœ¨è¿‡å»Nå¤©çš„æ¶¨è·Œå¹…
    2. å°†æ‰€æœ‰è‚¡ç¥¨æŒ‰æ¶¨è·Œå¹…æ’åº
    3. è®¡ç®—ç™¾åˆ†ä½æ’åï¼ˆ0-100ï¼‰
    """
    print(f"  -> Calculating RS Rating (lookback: {lookback_period} days)...")
    
    # ä¸ºæ¯åªè‚¡ç¥¨è®¡ç®—æ”¶ç›Šç‡
    def calc_return(group):
        """è®¡ç®—å•åªè‚¡ç¥¨çš„æ”¶ç›Šç‡"""
        if len(group) < lookback_period:
            return np.nan
        
        # è·å–æœ€æ–°ä»·æ ¼å’ŒNå¤©å‰çš„ä»·æ ¼
        latest_close = group.iloc[-1]
        old_close = group.iloc[-lookback_period] if len(group) >= lookback_period else group.iloc[0]
        
        if old_close > 0:
            return ((latest_close - old_close) / old_close) * 100
        return np.nan
    
    # æŒ‰è‚¡ç¥¨åˆ†ç»„ï¼Œè®¡ç®—æ¯åªè‚¡ç¥¨çš„æ”¶ç›Šç‡
    df['price_return'] = df.groupby('symbol')['close'].transform(calc_return)
    
    # å¯¹äºæœ€æ–°æ—¥æœŸï¼Œè®¡ç®—RS Rating
    latest_date = df['date'].max()
    latest_data = df[df['date'] == latest_date].copy()
    
    # ç§»é™¤æ²¡æœ‰æ”¶ç›Šç‡æ•°æ®çš„è‚¡ç¥¨
    valid_stocks = latest_data.dropna(subset=['price_return'])
    
    if len(valid_stocks) == 0:
        print("  -> âš ï¸ No valid stocks for RS Rating calculation")
        df['rs_rating'] = np.nan
        return df
    
    # è®¡ç®—ç™¾åˆ†ä½æ’åï¼ˆæ ¸å¿ƒç®—æ³•ï¼‰
    valid_stocks['rs_rating'] = valid_stocks['price_return'].rank(pct=True) * 99 + 1
    valid_stocks['rs_rating'] = valid_stocks['rs_rating'].round(1)
    
    # åˆå¹¶å›åŸæ•°æ®
    df = df.merge(
        valid_stocks[['symbol', 'rs_rating']],
        on='symbol',
        how='left',
        suffixes=('', '_new')
    )
    
    # å¦‚æœæœ‰æ–°çš„rs_ratingåˆ—ï¼Œä½¿ç”¨å®ƒ
    if 'rs_rating_new' in df.columns:
        df['rs_rating'] = df['rs_rating_new']
        df.drop('rs_rating_new', axis=1, inplace=True)
    
    print(f"  -> RS Rating calculated for {len(valid_stocks)} stocks")
    print(f"  -> RS Rating range: {valid_stocks['rs_rating'].min():.1f} - {valid_stocks['rs_rating'].max():.1f}")
    print(f"  -> RS Rating median: {valid_stocks['rs_rating'].median():.1f}")
    
    return df

def update_daily_metrics(supabase: Client, df: pd.DataFrame, target_date: str):
    """æ›´æ–°daily_metricsè¡¨"""
    print(f"  -> Updating daily_metrics for {target_date}...")
    
    # ç­›é€‰ç›®æ ‡æ—¥æœŸçš„æ•°æ®
    target_data = df[df['date'] == target_date].copy()
    
    if target_data.empty:
        print("  -> No data to update")
        return
    
    # å‡†å¤‡è¦æ›´æ–°çš„è®°å½•
    records = []
    for _, row in target_data.iterrows():
        record = {
            'symbol': row['symbol'],
            'date': row['date'],
            'ma5': float(row['ma5']) if pd.notna(row['ma5']) else None,
            'ma10': float(row['ma10']) if pd.notna(row['ma10']) else None,
            'ma20': float(row['ma20']) if pd.notna(row['ma20']) else None,
            'ma30': float(row['ma30']) if pd.notna(row['ma30']) else None,
            'ma50': float(row['ma50']) if pd.notna(row['ma50']) else None,
            'ma60': float(row['ma60']) if pd.notna(row['ma60']) else None,
            'ma120': float(row['ma120']) if pd.notna(row['ma120']) else None,
            'ma150': float(row['ma150']) if pd.notna(row['ma150']) else None,
            'ma200': float(row['ma200']) if pd.notna(row['ma200']) else None,
            'ma250': float(row['ma250']) if pd.notna(row['ma250']) else None,
            'high_52w': float(row['high_52w']) if pd.notna(row['high_52w']) else None,
            'low_52w': float(row['low_52w']) if pd.notna(row['low_52w']) else None,
            'rs_rating': float(row['rs_rating']) if pd.notna(row['rs_rating']) else None,
            'volume_ma10': int(row['volume_ma10']) if pd.notna(row['volume_ma10']) else None,
            'volume_ma30': int(row['volume_ma30']) if pd.notna(row['volume_ma30']) else None,
            'volume_ma60': int(row['volume_ma60']) if pd.notna(row['volume_ma60']) else None,
            'volume_ma90': int(row['volume_ma90']) if pd.notna(row['volume_ma90']) else None,
        }
        records.append(record)
    
    # æ‰¹é‡æ›´æ–°
    batch_size = 500
    for i in range(0, len(records), batch_size):
        batch = records[i:i+batch_size]
        supabase.table('daily_metrics').upsert(batch, on_conflict='symbol,date').execute()
    
    print(f"  -> âœ… Updated {len(records)} records in daily_metrics")

def main():
    print("=" * 70)
    print("ğŸš€ Calculate Technical Indicators (Pure Python Implementation)")
    print("=" * 70)
    
    if not SUPABASE_URL or not SUPABASE_KEY:
        print("âŒ Error: Supabase credentials not found")
        sys.exit(1)
    
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
    
    # è·å–æœ€æ–°äº¤æ˜“æ—¥
    target_date = get_latest_trading_date(supabase)
    print(f"\nğŸ“… Target date: {target_date}")
    
    try:
        # 1. è·å–å†å²æ•°æ®ï¼ˆéœ€è¦è¶³å¤Ÿé•¿çš„å†å²ï¼Œä»¥è®¡ç®—250æ—¥å‡çº¿ï¼‰
        df = fetch_historical_bars(supabase, days_back=300, target_date=target_date)
        
        if df.empty:
            print("âŒ No data found")
            sys.exit(1)
        
        # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
        df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')
        
        # æŒ‰symbolå’Œdateæ’åº
        df = df.sort_values(['symbol', 'date'])
        
        print(f"\nğŸ“Š Data loaded: {len(df)} records, {df['symbol'].nunique()} stocks")
        
        # 2. è®¡ç®—æ‰€æœ‰ç§»åŠ¨å¹³å‡çº¿
        ma_periods = [5, 10, 20, 30, 50, 60, 120, 150, 200, 250]
        df = calculate_moving_averages(df, ma_periods)
        
        # 3. è®¡ç®—52å‘¨é«˜ä½ç‚¹
        df = calculate_52w_high_low(df, window=200)
        
        # 4. è®¡ç®—æˆäº¤é‡å‡çº¿
        volume_ma_periods = [10, 30, 60, 90]
        df = calculate_volume_ma(df, volume_ma_periods)
        
        # 5. è®¡ç®—RS Ratingï¼ˆå…³é”®ï¼ï¼‰
        df = calculate_rs_rating_python(df, lookback_period=60)
        
        # 6. æ›´æ–°æ•°æ®åº“
        update_daily_metrics(supabase, df, target_date)
        
        print("\n" + "=" * 70)
        print("âœ… All indicators calculated successfully!")
        print("=" * 70)
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == '__main__':
    main()
