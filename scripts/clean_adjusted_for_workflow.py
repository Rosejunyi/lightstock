#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GitHub Actions æ¸…æ´—è„šæœ¬
æ¸…æ´— adjusted_parquet æ•°æ®ï¼Œä¿ç•™æ‰€æœ‰åˆ—
"""

import pandas as pd
from pathlib import Path
import logging
from tqdm import tqdm

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')

def clean_stock_data(input_file, output_file):
    """æ¸…æ´—å•ä¸ªæ–‡ä»¶ï¼Œä¿ç•™æ‰€æœ‰åˆ—"""
    try:
        df = pd.read_parquet(input_file)
        
        # ç¡®ä¿æ—¥æœŸæ ¼å¼å¹¶è®¾ä¸ºç´¢å¼•
        if 'date' in df.columns:
            df['date'] = pd.to_datetime(df['date'])
            df.set_index('date', inplace=True)
        elif 'æ—¥æœŸ' in df.columns:
            df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
            df.set_index('æ—¥æœŸ', inplace=True)
        else:
            logging.warning(f'{input_file.name}: æ²¡æœ‰æ—¥æœŸåˆ—')
            return False
        
        # æ’åºã€å»é‡ã€åˆ é™¤ç¼ºå¤±å€¼
        df.sort_index(inplace=True)
        df = df[~df.index.duplicated(keep='last')]
        df.dropna(inplace=True)
        
        if len(df) > 0:
            df.to_parquet(output_file, compression='snappy')
            return True
        return False
        
    except Exception as e:
        logging.error(f'{input_file.name}: {e}')
        return False

def main():
    print("="*50)
    print("  æ¸…æ´—å¤æƒæ•°æ®ï¼ˆä¿ç•™æ‰€æœ‰åˆ—ï¼‰")
    print("="*50)
    print()
    
    # è·¯å¾„
    base_dir = Path(__file__).parent.parent
    adjusted_dir = base_dir / 'data' / 'adjusted_parquet'
    cleaned_dir = base_dir / 'data' / 'cleaned_parquet'
    cleaned_dir.mkdir(exist_ok=True, parents=True)
    
    if not adjusted_dir.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {adjusted_dir}")
        return
    
    # è·å–æ‰€æœ‰æ–‡ä»¶
    files = list(adjusted_dir.glob('*.parquet'))
    print(f"ğŸ“ æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶")
    print()
    
    success = 0
    failed = 0
    skipped = 0
    
    for input_file in tqdm(files, desc="æ¸…æ´—è¿›åº¦"):
        output_file = cleaned_dir / input_file.name
        
        # è·³è¿‡å·²å­˜åœ¨ä¸”è¾ƒæ–°çš„æ–‡ä»¶
        if output_file.exists():
            if output_file.stat().st_mtime > input_file.stat().st_mtime:
                skipped += 1
                continue
        
        if clean_stock_data(input_file, output_file):
            success += 1
        else:
            failed += 1
    
    print()
    print("="*50)
    print(f"âœ… æˆåŠŸ: {success}")
    print(f"â­ï¸  è·³è¿‡: {skipped}")
    print(f"âŒ å¤±è´¥: {failed}")
    
    # ç»Ÿè®¡ç»“æœ
    cleaned_files = list(cleaned_dir.glob('*.parquet'))
    if cleaned_files:
        total_size = sum(f.stat().st_size for f in cleaned_files) / 1024 / 1024
        print(f"ğŸ“Š æ€»è®¡: {len(cleaned_files)} ä¸ªæ–‡ä»¶, {total_size:.2f} MB")
        
        # æ˜¾ç¤ºç¤ºä¾‹
        sample = cleaned_files[0]
        sample_df = pd.read_parquet(sample)
        print(f"\nğŸ“‹ ç¤ºä¾‹æ–‡ä»¶: {sample.name}")
        print(f"   åˆ—å: {list(sample_df.columns)}")
        print(f"   æ•°æ®é‡: {len(sample_df)} è¡Œ")
    
    print("="*50)

if __name__ == '__main__':
    main()
