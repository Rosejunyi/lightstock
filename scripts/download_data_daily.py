#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¯æ—¥å¢é‡æ›´æ–°é˜¿é‡Œäº‘è½»é‡æœåŠ¡å™¨è‚¡ç¥¨æ•°æ®è„šæœ¬
ç”¨äºGitHub Actionsè‡ªåŠ¨åŒ–
åªä¸‹è½½æœ€æ–°çš„æ•°æ®,ä¸é‡å¤ä¸‹è½½å†å²æ•°æ®
"""

import baostock as bs
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
import argparse
import sys
from tqdm import tqdm

class DailyStockUpdater:
    """æ¯æ—¥è‚¡ç¥¨æ•°æ®æ›´æ–°å™¨"""
    
    def __init__(self, output_dir="data/daily_parquet"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def get_date_range(self, recent_days=5, start_date=None, end_date=None):
        """
        è·å–è¦æ›´æ–°çš„æ—¥æœŸèŒƒå›´
        
        Args:
            recent_days: æœ€è¿‘Nä¸ªäº¤æ˜“æ—¥
            start_date: æŒ‡å®šå¼€å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: æŒ‡å®šç»“æŸæ—¥æœŸ (YYYY-MM-DD)
        """
        if start_date and end_date:
            return start_date, end_date
        
        # é»˜è®¤:æœ€è¿‘Nä¸ªäº¤æ˜“æ—¥
        end_date = datetime.now()
        start_date = end_date - timedelta(days=recent_days)
        
        return start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d')
    
    def get_all_stocks(self):
        """è·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç """
        print("ğŸ“‹ è·å–è‚¡ç¥¨åˆ—è¡¨...")
        
        # è·å–æ²ªæ·±Aè‚¡åˆ—è¡¨
        rs = bs.query_stock_basic()
        stock_list = []
        
        while rs.next():
            stock_list.append(rs.get_row_data()[0])  # è·å–è‚¡ç¥¨ä»£ç 
        
        print(f"âœ… å…±æ‰¾åˆ° {len(stock_list)} åªè‚¡ç¥¨")
        return stock_list
    
    def download_stock_data(self, stock_code, start_date, end_date):
        """
        ä¸‹è½½å•åªè‚¡ç¥¨çš„æ•°æ®
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç  (å¦‚ sh.600000)
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
        """
        try:
            # æŸ¥è¯¢æ—¥çº¿æ•°æ®
            rs = bs.query_history_k_data_plus(
                stock_code,
                "date,code,open,high,low,close,preclose,volume,amount,turn,pctChg",
                start_date=start_date,
                end_date=end_date,
                frequency="d",
                adjustflag="3"  # ä¸å¤æƒ
            )
            
            # æ”¶é›†æ•°æ®
            data_list = []
            while rs.next():
                data_list.append(rs.get_row_data())
            
            if not data_list:
                return None
            
            # è½¬æ¢ä¸ºDataFrame
            df = pd.DataFrame(data_list, columns=rs.fields)
            
            # æ•°æ®ç±»å‹è½¬æ¢
            numeric_cols = ['open', 'high', 'low', 'close', 'preclose', 
                          'volume', 'amount', 'turn', 'pctChg']
            for col in numeric_cols:
                df[col] = pd.to_numeric(df[col], errors='coerce')
            
            df['date'] = pd.to_datetime(df['date'])
            
            return df
            
        except Exception as e:
            print(f"âŒ {stock_code} ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    def update_or_append(self, stock_code, new_data):
        """
        æ›´æ–°æˆ–è¿½åŠ æ•°æ®åˆ°å·²æœ‰çš„parquetæ–‡ä»¶
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç  (å¦‚ sh.600000)
            new_data: æ–°ä¸‹è½½çš„æ•°æ®
        """
        # å»æ‰å‰ç¼€,åªä¿ç•™6ä½ä»£ç 
        code = stock_code.split('.')[-1]
        file_path = self.output_dir / f"{code}.parquet"
        
        if file_path.exists():
            # è¯»å–å·²æœ‰æ•°æ®
            existing_data = pd.read_parquet(file_path)
            
            # åˆå¹¶æ•°æ® (å»é‡)
            combined = pd.concat([existing_data, new_data], ignore_index=True)
            combined = combined.drop_duplicates(subset=['date'], keep='last')
            combined = combined.sort_values('date').reset_index(drop=True)
            
            # åªä¿å­˜æœ‰æ–°æ•°æ®çš„æƒ…å†µ
            if len(combined) > len(existing_data):
                combined.to_parquet(file_path, index=False, compression='snappy')
                return len(combined) - len(existing_data)  # è¿”å›æ–°å¢è®°å½•æ•°
            return 0
        else:
            # æ–°æ–‡ä»¶,ç›´æ¥ä¿å­˜
            new_data.to_parquet(file_path, index=False, compression='snappy')
            return len(new_data)
    
    def run(self, recent_days=5, start_date=None, end_date=None):
        """
        æ‰§è¡Œå¢é‡æ›´æ–°
        
        Args:
            recent_days: æœ€è¿‘Nä¸ªäº¤æ˜“æ—¥
            start_date: æŒ‡å®šå¼€å§‹æ—¥æœŸ
            end_date: æŒ‡å®šç»“æŸæ—¥æœŸ
        """
        print("=" * 60)
        print("ğŸ“Š æ¯æ—¥è‚¡ç¥¨æ•°æ®å¢é‡æ›´æ–°")
        print("=" * 60)
        
        # ç™»å½•baostock
        print("\nğŸ” ç™»å½•baostock...")
        lg = bs.login()
        if lg.error_code != '0':
            print(f"âŒ ç™»å½•å¤±è´¥: {lg.error_msg}")
            return False
        print("âœ… ç™»å½•æˆåŠŸ")
        
        try:
            # è·å–æ—¥æœŸèŒƒå›´
            start_date, end_date = self.get_date_range(recent_days, start_date, end_date)
            print(f"\nğŸ“… æ›´æ–°æ—¥æœŸèŒƒå›´: {start_date} åˆ° {end_date}")
            
            # è·å–è‚¡ç¥¨åˆ—è¡¨
            stock_list = self.get_all_stocks()
            
            # ç»Ÿè®¡
            total_stocks = len(stock_list)
            updated_count = 0
            failed_count = 0
            new_records = 0
            
            print(f"\nğŸš€ å¼€å§‹ä¸‹è½½æ•°æ®...")
            print(f"   æ€»è‚¡ç¥¨æ•°: {total_stocks}")
            print()
            
            # ä¸‹è½½æ•°æ®
            with tqdm(stock_list, desc="ä¸‹è½½è¿›åº¦") as pbar:
                for stock_code in pbar:
                    pbar.set_description(f"ä¸‹è½½ {stock_code}")
                    
                    # ä¸‹è½½æ•°æ®
                    df = self.download_stock_data(stock_code, start_date, end_date)
                    
                    if df is not None and len(df) > 0:
                        # æ›´æ–°æ–‡ä»¶
                        added = self.update_or_append(stock_code, df)
                        if added > 0:
                            updated_count += 1
                            new_records += added
                    else:
                        failed_count += 1
            
            # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            print("\n" + "=" * 60)
            print("ğŸ“Š æ›´æ–°å®Œæˆ!")
            print("=" * 60)
            print(f"âœ… æˆåŠŸæ›´æ–°: {updated_count} åªè‚¡ç¥¨")
            print(f"ğŸ“ æ–°å¢è®°å½•: {new_records} æ¡")
            print(f"â­ï¸  æ— æ–°æ•°æ®: {total_stocks - updated_count - failed_count} åª")
            print(f"âŒ å¤±è´¥: {failed_count} åª")
            print(f"ğŸ“‚ æ•°æ®ç›®å½•: {self.output_dir.absolute()}")
            print("=" * 60)
            
            return True
            
        except Exception as e:
            print(f"\nâŒ æ›´æ–°å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False
            
        finally:
            # ç™»å‡º
            bs.logout()
            print("\nğŸ‘‹ å·²ç™»å‡ºbaostock")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ¯æ—¥å¢é‡æ›´æ–°è‚¡ç¥¨æ•°æ®')
    parser.add_argument('--recent_days', type=int, default=5,
                      help='æ›´æ–°æœ€è¿‘Nä¸ªäº¤æ˜“æ—¥çš„æ•°æ® (é»˜è®¤5å¤©)')
    parser.add_argument('--start_date', type=str, default=None,
                      help='æŒ‡å®šå¼€å§‹æ—¥æœŸ YYYY-MM-DD')
    parser.add_argument('--end_date', type=str, default=None,
                      help='æŒ‡å®šç»“æŸæ—¥æœŸ YYYY-MM-DD')
    parser.add_argument('--output', type=str, default='data/daily_parquet',
                      help='è¾“å‡ºç›®å½• (é»˜è®¤: data/daily_parquet)')
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ›´æ–°å™¨
    updater = DailyStockUpdater(output_dir=args.output)
    
    # æ‰§è¡Œæ›´æ–°
    success = updater.run(
        recent_days=args.recent_days,
        start_date=args.start_date,
        end_date=args.end_date
    )
    
    # é€€å‡º
    sys.exit(0 if success else 1)


if __name__ == '__main__':
    main()
