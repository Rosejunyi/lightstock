#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™ºèƒ½è‚¡ç¥¨æ•°æ®æ›´æ–°è„šæœ¬ V3.3 - å®Œæ•´ä¿®æ­£ç‰ˆ
- ä¿®æ­£å¢é‡æ›´æ–°é€»è¾‘ï¼ˆå»é™¤3å¤©å›æº¯ï¼‰
- ä¿®æ­£è‚¡ç¥¨åˆ—è¡¨è·å–ï¼ˆå¢å¼ºè°ƒè¯•ï¼‰
"""

import baostock as bs
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
import subprocess
import os
from tqdm import tqdm


def check_server_latest_date():
    """æ£€æŸ¥æœåŠ¡å™¨æœ€æ–°æ–‡ä»¶çš„ä¿®æ”¹æ—¥æœŸ"""
    server_ip = os.environ.get('SERVER_IP')
    server_path = os.environ.get('SERVER_PATH', '/root/lightstock')
    
    if not server_ip:
        print("âš ï¸ æœªé…ç½®æœåŠ¡å™¨åœ°å€ï¼Œè·³è¿‡æ£€æŸ¥")
        return None
    
    print("ğŸ” æ£€æŸ¥æœåŠ¡å™¨æ•°æ®çŠ¶æ€...")
    print(f"æœåŠ¡å™¨: {server_ip}")
    
    try:
        check_cmd = f"""
ssh -o ConnectTimeout=10 -o StrictHostKeyChecking=no root@{server_ip} '
cd {server_path}/data/daily_parquet/ 2>/dev/null || exit 1

# è·å–æœ€æ–°ä¿®æ”¹çš„æ–‡ä»¶
latest_file=$(ls -t *.parquet 2>/dev/null | head -1)

if [ -z "$latest_file" ]; then
    echo "NO_FILES"
    exit 0
fi

# è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´æˆ³
file_time=$(stat -c %Y "$latest_file" 2>/dev/null || stat -f %m "$latest_file" 2>/dev/null)

echo "$latest_file|$file_time"
'
"""
        
        result = subprocess.run(
            check_cmd,
            shell=True,
            capture_output=True,
            text=True,
            timeout=30
        )
        
        if result.returncode != 0:
            print(f"âš ï¸ è¿æ¥æœåŠ¡å™¨å¤±è´¥")
            return None
        
        output = result.stdout.strip()
        
        if output == "NO_FILES":
            print("âš ï¸ æœåŠ¡å™¨ä¸Šæ²¡æœ‰æ•°æ®æ–‡ä»¶")
            return None
        
        if '|' not in output:
            print(f"âš ï¸ æ— æ³•è§£ææœåŠ¡å™¨å“åº”")
            return None
        
        filename, timestamp = output.split('|')
        file_date = datetime.fromtimestamp(int(timestamp))
        
        days_old = (datetime.now() - file_date).days
        
        print(f"âœ… æœåŠ¡å™¨æœ€æ–°æ–‡ä»¶: {filename}")
        print(f"âœ… æ–‡ä»¶ä¿®æ”¹æ—¶é—´: {file_date.strftime('%Y-%m-%d')}")
        print(f"âœ… è·ä»Š: {days_old} å¤©")
        
        return file_date.date()
            
    except Exception as e:
        print(f"âš ï¸ æ£€æŸ¥å¤±è´¥: {e}")
        return None


def get_stock_list():
    """è·å–æ‰€æœ‰è‚¡ç¥¨åˆ—è¡¨ï¼ˆå¢å¼ºè°ƒè¯•ç‰ˆï¼‰"""
    print("ğŸ“‹ è·å–è‚¡ç¥¨åˆ—è¡¨...")
    
    try:
        # è·å–å½“å‰æ—¥æœŸ
        today = datetime.now().strftime("%Y-%m-%d")
        print(f"æŸ¥è¯¢æ—¥æœŸ: {today}")
        
        # æŸ¥è¯¢æ‰€æœ‰è‚¡ç¥¨
        rs = bs.query_all_stock(day=today)
        
        # æ£€æŸ¥æŸ¥è¯¢ç»“æœ
        if rs.error_code != '0':
            print(f"âŒ query_all_stock æŸ¥è¯¢å¤±è´¥")
            print(f"   é”™è¯¯ç : {rs.error_code}")
            print(f"   é”™è¯¯ä¿¡æ¯: {rs.error_msg}")
            print("\nå°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ³•...")
            return get_stock_list_fallback()
        
        # è·å–æ•°æ®
        data = []
        count = 0
        while (rs.error_code == '0') and rs.next():
            data.append(rs.get_row_data())
            count += 1
        
        print(f"ğŸ“Š ä»baostockè·å–åˆ° {len(data)} æ¡è®°å½•ï¼ˆå¾ªç¯ {count} æ¬¡ï¼‰")
        
        if len(data) < 100:
            print(f"âš ï¸ è·å–çš„è®°å½•æ•°å¤ªå°‘ï¼ˆ{len(data)}æ¡ï¼‰ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
            return get_stock_list_fallback()
        
        # åˆ›å»ºDataFrame
        df = pd.DataFrame(data, columns=rs.fields)
        
        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        print(f"ğŸ“‹ åˆ—å: {list(df.columns)}")
        print(f"ğŸ“‹ æ•°æ®ç¤ºä¾‹ï¼ˆå‰3è¡Œï¼‰:")
        print(df.head(3))
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ type åˆ—
        if 'type' in df.columns:
            print("âœ… æ‰¾åˆ° 'type' åˆ—")
            # æ‰“å° type åˆ—çš„å”¯ä¸€å€¼
            print(f"   type åˆ—çš„å”¯ä¸€å€¼: {df['type'].unique()}")
            
            # 1 = è‚¡ç¥¨, 2 = æŒ‡æ•°
            stocks = df[df['type'] == '1']['code'].tolist()
            print(f"âœ… ä½¿ç”¨ type è¿‡æ»¤ï¼Œè·å–åˆ° {len(stocks)} åªè‚¡ç¥¨")
        else:
            print("âš ï¸ æ²¡æœ‰ 'type' åˆ—ï¼Œä½¿ç”¨ä»£ç æ ¼å¼è¿‡æ»¤")
            stocks = filter_stocks_by_code(df)
        
        if stocks and len(stocks) > 0:
            print(f"ğŸ“‹ ç¤ºä¾‹è‚¡ç¥¨ä»£ç ï¼ˆå‰10ä¸ªï¼‰: {stocks[:10]}")
            return stocks
        else:
            print("âŒ è¿‡æ»¤åæ²¡æœ‰è‚¡ç¥¨ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•")
            return get_stock_list_fallback()
        
    except Exception as e:
        print(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        print("\nå°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ³•...")
        return get_stock_list_fallback()


def filter_stocks_by_code(df):
    """é€šè¿‡ä»£ç æ ¼å¼è¿‡æ»¤è‚¡ç¥¨"""
    all_codes = df['code'].tolist()
    
    # æ’é™¤å·²çŸ¥æŒ‡æ•°
    exclude_list = [
        'sh.000001', 'sh.000300', 
        'sz.399001', 'sz.399006', 'sz.399005', 'sz.399300'
    ]
    
    stocks = []
    for code in all_codes:
        if code in exclude_list:
            continue
        
        # æå–ä»£ç æ•°å­—éƒ¨åˆ†
        code_num = code.split('.')[-1]
        
        # è‚¡ç¥¨ä»£ç å¿…é¡»æ˜¯6ä½æ•°å­—ï¼Œä¸”ä¸ä»¥399å¼€å¤´ï¼ˆæ·±è¯æŒ‡æ•°ï¼‰
        if len(code_num) == 6 and code_num.isdigit():
            if not code_num.startswith('399'):
                stocks.append(code)
    
    print(f"âœ… ä»£ç æ ¼å¼è¿‡æ»¤ï¼Œè·å–åˆ° {len(stocks)} åªè‚¡ç¥¨")
    return stocks


def get_stock_list_fallback():
    """å¤‡ç”¨æ–¹æ³•ï¼šç”Ÿæˆè‚¡ç¥¨ä»£ç èŒƒå›´"""
    print("ğŸ“‹ ä½¿ç”¨å¤‡ç”¨æ–¹æ³•ï¼šç”Ÿæˆè‚¡ç¥¨ä»£ç ...")
    
    stocks = []
    
    # æ²ªå¸‚Aè‚¡ï¼š600000-605000, 601000-605000ï¼ˆå¸¸è§èŒƒå›´ï¼‰
    print("  ç”Ÿæˆæ²ªå¸‚Aè‚¡...")
    for prefix in ['600', '601', '603', '605']:
        for i in range(1000):
            stocks.append(f"sh.{prefix}{i:03d}")
    
    # æ·±å¸‚ä¸»æ¿ï¼š000002-000999ï¼ˆæ’é™¤000001æŒ‡æ•°ï¼‰
    print("  ç”Ÿæˆæ·±å¸‚ä¸»æ¿...")
    for i in range(2, 1000):
        stocks.append(f"sz.{i:06d}")
    
    # ä¸­å°æ¿ï¼š002000-002999
    print("  ç”Ÿæˆä¸­å°æ¿...")
    for i in range(2000, 3000):
        stocks.append(f"sz.{i:06d}")
    
    # åˆ›ä¸šæ¿ï¼š300000-300999
    print("  ç”Ÿæˆåˆ›ä¸šæ¿...")
    for i in range(300000, 301000):
        stocks.append(f"sz.{i}")
    
    # ç§‘åˆ›æ¿ï¼š688000-688999
    print("  ç”Ÿæˆç§‘åˆ›æ¿...")
    for i in range(688000, 689000):
        stocks.append(f"sh.{i}")
    
    print(f"âœ… å¤‡ç”¨æ–¹æ³•ç”Ÿæˆäº† {len(stocks)} ä¸ªä»£ç ")
    print(f"ğŸ“‹ ç¤ºä¾‹: {stocks[:10]}")
    
    return stocks


def get_index_list():
    """è·å–éœ€è¦çš„æŒ‡æ•°åˆ—è¡¨"""
    return ["sh.000001", "sh.000300", "sz.399001", "sz.399006"]


def download_stock_data(code, start_date, end_date):
    """ä¸‹è½½å•åªè‚¡ç¥¨æ•°æ®"""
    try:
        pure_code = code.split('.')[-1]
        
        rs = bs.query_history_k_data_plus(
            code,
            "date,code,open,high,low,close,volume,amount,adjustflag,turn,tradestatus,pctChg,peTTM,pbMRQ,psTTM,pcfNcfTTM,isST",
            start_date=start_date,
            end_date=end_date,
            frequency="d",
            adjustflag="3"
        )
        
        data = []
        while (rs.error_code == '0') and rs.next():
            data.append(rs.get_row_data())
        
        if not data:
            return None
        
        df = pd.DataFrame(data, columns=rs.fields)
        filename = f"{pure_code}.parquet"
        
        return filename, df
        
    except Exception as e:
        return None


def download_index_data(code, start_date, end_date):
    """ä¸‹è½½æŒ‡æ•°æ•°æ®"""
    try:
        rs = bs.query_history_k_data_plus(
            code,
            "date,code,open,high,low,close,volume,amount",
            start_date=start_date,
            end_date=end_date,
            frequency="d"
        )
        
        data = []
        while (rs.error_code == '0') and rs.next():
            data.append(rs.get_row_data())
        
        if not data:
            return None
        
        df = pd.DataFrame(data, columns=rs.fields)
        filename = f"{code}.parquet"
        
        return filename, df
        
    except Exception as e:
        return None


def main():
    """ä¸»å‡½æ•°"""
    print("="*50)
    print("  æ™ºèƒ½è‚¡ç¥¨æ•°æ®æ›´æ–° V3.3")
    print("="*50)
    print()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path("data/daily_parquet")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("V3.3 æ›´æ–°ç­–ç•¥:")
    print("  âœ… è‚¡ç¥¨æ–‡ä»¶: çº¯æ•°å­—å‘½å (å¦‚ 000001.parquet)")
    print("  âœ… æŒ‡æ•°æ–‡ä»¶: å®Œæ•´æ ¼å¼ (å¦‚ sh.000001.parquet)")
    print("  âœ… å¢é‡æ›´æ–°: ç¼ºå‡ å¤©è¡¥å‡ å¤©ï¼Œä¸å›æº¯")
    print("  âœ… å¢å¼ºè°ƒè¯•: è¯¦ç»†æ—¥å¿—è¾“å‡º")
    print()
    
    # æ£€æŸ¥æœåŠ¡å™¨æ•°æ®çŠ¶æ€
    server_latest = check_server_latest_date()
    
    # ç¡®å®šæ›´æ–°ç­–ç•¥
    today = datetime.now().date()
    
    if server_latest:
        days_diff = (today - server_latest).days
        
        print(f"\nğŸ“Š æ›´æ–°ç­–ç•¥:")
        print(f"   æœåŠ¡å™¨æœ€æ–°: {server_latest}")
        print(f"   ä»Šå¤©æ—¥æœŸ: {today}")
        print(f"   ç›¸å·®: {days_diff} å¤©")
        print()
        
        if days_diff <= 0:
            print("âœ… æœåŠ¡å™¨æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°")
            return
        
        # ä»æœåŠ¡å™¨æœ€æ–°æ—¥æœŸçš„ä¸‹ä¸€å¤©å¼€å§‹
        start_date = (server_latest + timedelta(days=1)).strftime("%Y-%m-%d")
        print(f"â© å¢é‡æ›´æ–°: ä» {start_date} åˆ° {today}")
        print(f"   éœ€è¦è¡¥å…… {days_diff} å¤©æ•°æ®")
        print()
        
    else:
        # é¦–æ¬¡ä¸‹è½½ï¼Œä»3ä¸ªæœˆå‰å¼€å§‹
        start_date = (today - timedelta(days=90)).strftime("%Y-%m-%d")
        print(f"ğŸ“¥ é¦–æ¬¡ä¸‹è½½: ä» {start_date} å¼€å§‹ï¼ˆæœ€è¿‘3ä¸ªæœˆï¼‰")
        print()
    
    end_date = today.strftime("%Y-%m-%d")
    
    print(f"ğŸ“… ä¸‹è½½åŒºé—´: {start_date} ~ {end_date}")
    print()
    
    # ç™»å½•
    print("ğŸ” ç™»å½•baostock...")
    lg = bs.login()
    if lg.error_code != '0':
        print(f"âŒ ç™»å½•å¤±è´¥: {lg.error_msg}")
        return
    print("âœ… ç™»å½•æˆåŠŸ")
    print()
    
    try:
        # ä¸‹è½½è‚¡ç¥¨æ•°æ®
        print("="*50)
        print("ğŸ“Š å¼€å§‹ä¸‹è½½è‚¡ç¥¨æ•°æ®")
        print("="*50)
        print()
        
        stocks = get_stock_list()
        
        if not stocks or len(stocks) == 0:
            print("âŒ æœªè·å–åˆ°è‚¡ç¥¨åˆ—è¡¨ï¼Œç¨‹åºç»ˆæ­¢")
            return
        
        print(f"\nå¼€å§‹ä¸‹è½½ {len(stocks)} åªè‚¡ç¥¨...")
        print()
        
        success_count = 0
        skip_count = 0
        
        for code in tqdm(stocks, desc="ä¸‹è½½è‚¡ç¥¨"):
            result = download_stock_data(code, start_date, end_date)
            if result:
                filename, df = result
                filepath = output_dir / filename
                
                # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œåˆå¹¶æ•°æ®
                if filepath.exists():
                    try:
                        old_df = pd.read_parquet(filepath)
                        df = pd.concat([old_df, df], ignore_index=True)
                        df.drop_duplicates(subset=['date'], keep='last', inplace=True)
                        df.sort_values('date', inplace=True)
                    except:
                        pass
                
                df.to_parquet(filepath, index=False)
                success_count += 1
            else:
                skip_count += 1
        
        print(f"\nâœ… è‚¡ç¥¨æ•°æ®ä¸‹è½½å®Œæˆ:")
        print(f"   æˆåŠŸ: {success_count}")
        print(f"   è·³è¿‡: {skip_count}")
        print()
        
        # ä¸‹è½½æŒ‡æ•°æ•°æ®
        print("="*50)
        print("ğŸ“ˆ å¼€å§‹ä¸‹è½½æŒ‡æ•°æ•°æ®")
        print("="*50)
        print()
        
        indexes = get_index_list()
        
        for code in tqdm(indexes, desc="ä¸‹è½½æŒ‡æ•°"):
            result = download_index_data(code, start_date, end_date)
            if result:
                filename, df = result
                filepath = output_dir / filename
                
                # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œåˆå¹¶æ•°æ®
                if filepath.exists():
                    try:
                        old_df = pd.read_parquet(filepath)
                        df = pd.concat([old_df, df], ignore_index=True)
                        df.drop_duplicates(subset=['date'], keep='last', inplace=True)
                        df.sort_values('date', inplace=True)
                    except:
                        pass
                
                df.to_parquet(filepath, index=False)
                print(f"  âœ… {filename}")
        
        print("\nâœ… æŒ‡æ•°æ•°æ®ä¸‹è½½å®Œæˆ")
        print()
        
        # ç»Ÿè®¡
        total_files = len(list(output_dir.glob("*.parquet")))
        print("="*50)
        print("ğŸ“Š ä¸‹è½½å®Œæˆç»Ÿè®¡")
        print("="*50)
        print(f"æ€»æ–‡ä»¶æ•°: {total_files}")
        print(f"è¾“å‡ºç›®å½•: {output_dir.absolute()}")
        
    except Exception as e:
        print(f"\nâŒ ä¸‹è½½è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        
    finally:
        bs.logout()
        print("\nâœ… å·²ç™»å‡ºbaostock")


if __name__ == "__main__":
    main()
